import streamlit as st
import pandas as pd
import numpy as np
# import seaborn as sns # Note: Seaborn imported but not used in the provided code for plotting
# from sklearn.metrics import ConfusionMatrixDisplay # Note: ConfusionMatrixDisplay imported but not used directly in the provided code for plotting
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_auc_score

# Importar os modelos espec√≠ficos utilizados ou referenciados
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier
from sklearn.tree import plot_tree
import matplotlib.pyplot as plt # Para exibir a √°rvore de decis√£o


import time
import plotly.express as px
import plotly.graph_objects as go
from streamlit_option_menu import option_menu

import joblib
import os

# --- Configura√ß√£o da P√°gina ---
st.set_page_config(
    page_title="Sistema de Interven√ß√£o Estudantil",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- Estilo CSS Personalizado ---
st.markdown("""
<style>
    /* Headers */
    .main-header {
        font-size: 2.8rem;
        color: #1A237E;
        text-align: center;
        margin-bottom: 1.5rem;
        font-weight: bold;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
    }
    .sub-header {
        font-size: 2rem;
        color: #283593;
        margin-top: 2rem;
        margin-bottom: 1rem;
        font-weight: bold;
        border-bottom: 2px solid #C5CAE9;
        padding-bottom: 0.5rem;
    }
    .info-text {
        font-size: 1rem;
        color: #424242;
        margin-bottom: 1rem;
        line-height: 1.6;
    }
    /* Cards */
    .metric-card {
        background-color: #E8EAF6;
        border-left: 6px solid #3F51B5;
        border-radius: 10px;
        padding: 1.5rem;
        margin-bottom: 1.5rem;
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.15);
    }
     /* Style for st.metric value - Streamlit's built-in metric uses different classes */
    div[data-testid="stMetric"] label div {
        font-size: 1rem !important;
        color: #555 !important;
    }
     div[data-testid="stMetric"] div[data-testid="stMetricDelta"] div {
         font-size: 1.8rem !important;
         font-weight: bold !important;
         color: #1A237E !important;
     }
    /* Button */
    .stButton > button {
        background-color: #3F51B5;
        color: white;
        font-weight: bold;
        padding: 0.75rem 1.5rem;
        border-radius: 5px;
        border: none;
        cursor: pointer;
        transition: background-color 0.3s ease;
        font-size: 1.1rem;
    }
    .stButton > button:hover {
        background-color: #303F9F;
    }
     /* Adjust sidebar width */
    section[data-testid="stSidebar"] {
        width: 300px !important;
        background-color: #f1f3f4;
    }
    /* Style for tabs */
    .stTabs [data-baseweb="tab-list"] {
		gap: 24px;
    }

    .stTabs [data-baseweb="tab"] {
		height: 50px;
		white-space: pre-wrap;
		background-color: #E8EAF6;
		border-radius: 4px 4px 0 0;
		gap: 10px;
		padding: 10px 20px;
        font-size: 1rem;
        font-weight: bold;
    }

    .stTabs [data-baseweb="tab"] svg {
		color: #3F51B5;
    }

    .stTabs [data-baseweb="tab"]:hover {
		background-color: #C5CAE9;
    }

    .stTabs [data-baseweb="tab"][aria-selected="true"] {
		background-color: #3F51B5;
		color: white;
		border-bottom: 3px solid #FFC107;
    }
    .stTabs [data-baseweb="tab"][aria-selected="true"] svg {
		color: white;
    }
     /* Style for st.info, st.warning, st.error */
    div[data-testid="stAlert"] {
        font-size: 1rem;
        padding: 1rem;
        border-radius: 5px;
        margin-bottom: 1.5rem;
    }

    /* CSS para o Grid Layout na Previs√£o Individual */
    .input-grid-container {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); /* 4 colunas (ajust√°vel), min 250px largura */
        gap: 20px; /* Espa√ßamento entre os itens do grid */
        margin-bottom: 20px;
    }
    .grid-item {
        display: flex; /* Usa flexbox dentro do item para empilhar conte√∫do */
        flex-direction: column;
        /* Optional: add padding or border for visual separation */
        /* border: 1px solid #e0e0e0; */
        /* padding: 15px; */
        /* border-radius: 8px; */
    }
     /* Ajusta o estilo do st.info para caber melhor */
    .grid-item div[data-testid="stAlert"] {
        margin-top: 5px; /* Pequena margem acima do info box */
        margin-bottom: 5px; /* Pequena margem abaixo do info box */
        padding: 10px; /* Reduz padding interno */
        font-size: 0.9rem; /* Reduz tamanho da fonte */
        line-height: 1.4;
    }

    /* Opcional: Ajustar o tamanho do st.number_input e st.selectbox dentro do grid item */
     .grid-item div[data-testid="stNumberInput"],
     .grid-item div[data-testid="stselectbox"] {
         margin-top: 5px;
     }
     /* Estilo para o nome da feature e a descri√ß√£o no grid item */
     .grid-item .feature-label {
         font-weight: bold; /* Nome da feature em negrito */
         margin-bottom: 5px; /* Espa√ßo abaixo do nome */
     }
     /* CSS para a descri√ß√£o pequena entre par√™ntesis */
     .small-description {
         font-size: 0.8em; /* Tamanho menor, 80% do tamanho normal */
         font-weight: normal; /* N√£o negrito */
         color: #555; /* Cor um pouco mais clara */
         margin-left: 5px; /* Espa√ßo entre o nome e a descri√ß√£o */
     }


</style>
""", unsafe_allow_html=True)

# --- Mapeamentos para features Ordinais Num√©ricas ---
ORDINAL_MAPPINGS = {
    'Medu': {0: 'Nenhuma', 1: 'Ensino Fund. (4¬™ s√©rie)', 2: 'Ensino Fund. (5¬™-9¬™ s√©rie)', 3: 'Ensino M√©dio', 4: 'Ensino Superior'},
    'Fedu': {0: 'Nenhuma', 1: 'Ensino Fund. (4¬™ s√©rie)', 2: 'Ensino Fund. (5¬™-9¬™ s√©rie)', 3: 'Ensino M√©dio', 4: 'Ensino Superior'},
    'traveltime': {1: '<15 min', 2: '15-30 min', 3: '30-60 min', 4: '>60 min'},
    'studytime': {1: '<2 horas', 2: '2 a 5 horas', 3: '5 a 10 horas', 4: '>10 horas'},
    'failures': {0: '0 falhas', 1: '1 falha', 2: '2 falhas', 3: '3+ falhas'}, # failures tem valores 0, 1, 2, 3+. O dataset pode ter mais que 3 falhas, mas 3+ √© o m√°ximo geralmente visto.
    'famrel': {1: 'Muito Ruim', 2: 'Ruim', 3: 'Regular', 4: 'Bom', 5: 'Excelente'},
    'freetime': {1: 'Muito Pouco', 2: 'Pouco', 3: 'M√©dio', 4: 'Muito', 5: 'Muito Muito'},
    'goout': {1: 'Muito Raramente', 2: 'Raramente', 3: 'Ocasionalmente', 4: 'Frequentemente', 5: 'Muito Frequentemente'},
    'Dalc': {1: 'Muito Baixo', 2: 'Baixo', 3: 'M√©dio', 4: 'Alto', 5: 'Muito Alto'},
    'Walc': {1: 'Muito Baixo', 2: 'Baixo', 3: 'M√©dio', 4: 'Alto', 5: 'Muito Alto'},
    'health': {1: 'Muito Ruim', 2: 'Ruim', 3: 'Regular', 4: 'Bom', 5: 'Excelente'},
    # 'age' e 'absences' s√£o num√©ricas cont√≠nuas/count, n√£o ordinais em escala
}

# Lista de features num√©ricas que representam escalas ordinais e para as quais temos mapeamentos
ordinal_numeric_features_to_map = list(ORDINAL_MAPPINGS.keys())

# --- Descri√ß√£o Curta das Caracter√≠sticas (Para a Previs√£o Individual) ---
feature_descriptions_short = {
    "school": "Escola",
    "sex": "G√™nero",
    "age": "Idade",
    "address": "Resid√™ncia",
    "famsize": "Tamanho fam√≠lia",
    "Pstatus": "Status pais",
    "Medu": "Escolaridade m√£e",
    "Fedu": "Escolaridade pai",
    "Mjob": "Ocupa√ß√£o m√£e",
    "Fjob": "Ocupa√ß√£o pai",
    "reason": "Motivo escola",
    "guardian": "Guardi√£o",
    "traveltime": "Tempo viagem",
    "studytime": "Tempo estudo",
    "failures": "Reprova√ß√µes",
    "schoolsup": "Apoio escola",
    "famsup": "Apoio fam√≠lia",
    "paid": "Aulas pagas",
    "activities": "Atividades extra",
    "nursery": "Frequentou creche",
    "higher": "Deseja superior",
    "internet": "Acesso internet",
    "romantic": "Relacionamento",
    "famrel": "Qualidade rela√ß√µes familiares",
    "freetime": "Tempo livre",
    "goout": "Sair c/amigos",
    "Dalc": "√Ålcool dias semana",
    "Walc": "√Ålcool fins semana",
    "health": "Estado sa√∫de",
    "absences": "Faltas",
    "passed": "Aprovado" # Descri√ß√£o curta aqui para ficar bem na previs√£o
}

# --- Descri√ß√£o Completa das Caracter√≠sticas (Para a Documenta√ß√£o) ---
full_feature_descriptions = {
    "school": "Escola do estudante (GP ou MS)",
    "sex": "G√™nero do estudante (F ou M)",
    "age": "Idade do estudante",
    "address": "Localiza√ß√£o da resid√™ncia (Urbana ou Rural)",
    "famsize": "Tamanho da fam√≠lia (Maior que 3 ou Menor/Igual a 3)",
    "Pstatus": "Status de coabita√ß√£o dos pais (Moram juntos ou Separados)",
    "Medu": "N√≠vel de escolaridade da m√£e (0: Nenhuma a 4: Ensino Superior)",
    "Fedu": "N√≠vel de escolaridade do pai (0: Nenhuma a 4: Ensino Superior)",
    "Mjob": "Ocupa√ß√£o da m√£e (teacher, health, services, at_home, other)",
    "Fjob": "Ocupa√ß√£o do pai (teacher, health, services, at_home, other)",
    "reason": "Motivo pela escolha da escola (home, reputation, course, other)",
    "guardian": "Guardi√£o do estudante (mother, father, other)",
    "traveltime": "Tempo de viagem para a escola (1: <15 min a 4: >60 min)",
    "studytime": "Tempo de estudo semanal (1: <2 horas a 4: >10 horas)",
    "failures": "N√∫mero de reprova√ß√µes anteriores (0 a 3+)",
    "schoolsup": "Apoio educacional extra da escola (yes ou no)",
    "famsup": "Apoio educacional familiar (yes ou no)",
    "paid": "Fez aulas pagas extra (yes ou no)",
    "activities": "Participa de atividades extracurriculares (yes ou no)",
    "nursery": "Frequentou creche/pr√©-escola (yes ou no)",
    "higher": "Deseja cursar ensino superior (yes ou no)",
    "internet": "Tem acesso √† internet em casa (yes ou no)",
    "romantic": "Est√° em relacionamento rom√¢ntico (yes ou no)",
    "famrel": "Qualidade dos relacionamentos familiares (1: muito ruim a 5: excelente)",
    "freetime": "Tempo livre ap√≥s a escola (1: muito pouco a 5: muito)",
    "goout": "Frequ√™ncia com que sai com amigos (1: muito raramente a 5: muito frequentemente)",
    "Dalc": "Consumo de √°lcool em dias de semana (1: muito baixo a 5: muito alto)",
    "Walc": "Consumo de √°lcool em fins de semana (1: muito baixo a 5: muito alto)",
    "health": "Estado de sa√∫de atual (1: muito ruim a 5: muito bom)",
    "absences": "N√∫mero de faltas escolares",
    "passed": "O estudante foi aprovado (yes ou no) - Vari√°vel Alvo" # Mantido "- Vari√°vel Alvo" aqui para clareza na documenta√ß√£o
}
# Fun√ß√£o para carregar um modelo espec√≠fico, com caching
@st.cache_resource
def load_specific_model(model_filename):
    artefacts_path = 'artefacts/'
    model_path = os.path.join(artefacts_path, model_filename)
    try:
        loaded_model = joblib.load(model_path)
        # st.success(f"‚úÖ Modelo '{model_filename}' carregado com sucesso!") # Pode ser muito verboso
        return loaded_model
    except FileNotFoundError:
        st.error(f"‚ùå Erro: O ficheiro do modelo '{model_filename}' n√£o foi encontrado na pasta 'artefacts/'.")
        return None
    except Exception as e:
        st.error(f"‚ùå Ocorreu um erro ao carregar o modelo '{model_filename}': {e}")
        return None


# Fun√ß√£o para exibir anima√ß√£o de carregamento
def loading_animation(text="Processando..."):
    progress_text = text
    my_bar = st.progress(0, text=progress_text)

    for percent_complete in range(100):
        time.sleep(0.01)
        my_bar.progress(percent_complete + 1, text=progress_text)
    time.sleep(0.5)
    my_bar.empty()

# Fun√ß√£o para gerar matriz de confus√£o interativa
def plot_confusion_matrix_interactive(y_true, y_pred, class_names=None):
    cm = confusion_matrix(y_true, y_pred)

    fig = go.Figure(data=go.Heatmap(
        z=cm,
        x=class_names,
        y=class_names,
        colorscale='Blues',
        showscale=True,
        text=cm,
        texttemplate="%{text}",
        textfont={"size": 20},
        hoverinfo="x+y+z",
    ))

    fig.update_layout(
        title='Matriz de Confus√£o',
        xaxis_title='Valores Previstos',
        yaxis_title='Valores Reais',
        xaxis=dict(side='top'),
        yaxis=dict(autorange="reversed"),
        margin=dict(t=50, b=50, l=50, r=50),
    )

    return fig, cm

# Fun√ß√£o para plotar matriz quadrada com mapa de calor (mais gen√©rica, mantida)
def plot_square_matrix_heatmap(matrix, title="Matriz Quadrada", x_labels=None, y_labels=None):
    matrix_list = [[None if pd.isna(val) else float(val) for val in row] for row in matrix]
    text_matrix = [[None if pd.isna(val) else f"{val:.2f}" for val in row] for row in matrix]

    fig = go.Figure(data=go.Heatmap(
        z=matrix_list,
        x=x_labels,
        y=y_labels,
        colorscale='Viridis',
        showscale=True,
        text=text_matrix,
        texttemplate="%{text}",
        hoverinfo="x+y+z",
    ))

    fig.update_layout(
        title=title,
        margin=dict(t=50, b=50, l=50, r=50),
    )

    return fig

# Fun√ß√£o para visualizar matriz de correla√ß√£o (usando plotly express)
def plot_correlation_matrix_px(df):
    df_numeric = df.select_dtypes(include=np.number)

    if df_numeric.empty:
         return None, None

    corr = df_numeric.corr()

    fig = px.imshow(
        corr,
        labels=dict(color="Correla√ß√£o"),
        x=corr.columns,
        y=corr.columns,
        color_continuous_scale='RdBu_r',
        range_color=[-1, 1],
        aspect="auto",
        text_auto=".2f",
    )

    fig.update_layout(
        title="Matriz de Correla√ß√£o",
        margin=dict(t=50, b=50, l=50, r=50),
    )

    return fig, corr

# Fun√ß√£o para analisar propriedades de uma matriz quadrada
def analyze_square_matrix(matrix, title="An√°lise de Matriz"):
    st.markdown(f'<h3 class="sub-header">{title}</h3>', unsafe_allow_html=True)

    if not isinstance(matrix, np.ndarray) or matrix.ndim != 2 or matrix.shape[0] != matrix.shape[1]:
        st.error("Input inv√°lido: A matriz deve ser um array NumPy quadrado e 2D.")
        return

    size = matrix.shape[0]
    st.write(f"**Dimens√£o da matriz:** {size}x{size}")

    trace = np.trace(matrix)
    st.write(f"**Tra√ßo da matriz:** {trace:.4f}")
    st.info("O tra√ßo √© a soma dos elementos na diagonal principal da matriz.")

    try:
        det = np.linalg.det(matrix)
        st.write(f"**Determinante:** {det:.4e}")
        if abs(det) < 1e-9:
            st.warning("‚ö†Ô∏è O determinante √© pr√≥ximo de zero...")
        else:
             st.success("‚úÖ O determinante sugere que a matriz n√£o √© singular.")
        st.info("O determinante indica se a matriz √© invert√≠vel...")
    except np.linalg.LinAlgError:
        st.error("‚ùå N√£o foi poss√≠vel calcular o determinante...")
        det = None
    except Exception as e:
        st.error(f"‚ùå Ocorreu um erro ao calcular o determinante: {e}")


    st.write("**Valores pr√≥prios (Eigenvalues):**")
    try:
        eigenvalues = np.linalg.eigvals(matrix)
        sorted_eigenvalues = np.sort(np.abs(eigenvalues))[::-1]

        # Exibir apenas alguns valores pr√≥prios
        max_eigen_display = min(10, len(sorted_eigenvalues)) # Display max 10 eigenvalues
        for i, val in enumerate(sorted_eigenvalues[:max_eigen_display]):
            # Find the original eigenvalue corresponding to this magnitude
            original_val = eigenvalues[np.where(np.isclose(np.abs(eigenvalues), val))[0][0]]
            st.write(f"Œª{i+1} (Magnitude) = {val:.4f} (Original: {original_val:.4f})")
        if len(sorted_eigenvalues) > max_eigen_display:
            st.write("...")


        if any(abs(val) < 1e-9 for val in eigenvalues): # Verificar se ALGUM valor pr√≥prio √© perto de zero
             st.warning("‚ö†Ô∏è Alguns valores pr√≥prios s√£o pr√≥ximos de zero...")
        else:
             st.success("‚úÖ Os valores pr√≥prios indicam que a matriz n√£o tem dire√ß√µes nulas...")
        st.info("Valores pr√≥prios representam os fatores de escala...")

    except np.linalg.LinAlgError:
        st.error("‚ùå N√£o foi poss√≠vel calcular os valores pr√≥prios.")
    except Exception as e:
        st.error(f"‚ùå Ocorreu um erro ao calcular os valores pr√≥prios: {e}")


    try:
        condition_number = np.linalg.cond(matrix)
        st.write(f"**N√∫mero de Condi√ß√£o:** {condition_number:.4e}")
        if condition_number > 1000:
            st.warning("‚ö†Ô∏è Alto n√∫mero de condi√ß√£o. A matriz √© mal condicionada...")
        else:
            st.success("‚úÖ N√∫mero de condi√ß√£o razo√°vel. A matriz est√° bem condicionada.")
        st.info("O n√∫mero de condi√ß√£o mede a sensibilidade...")
    except np.linalg.LinAlgError:
         st.error("‚ùå N√£o foi poss√≠vel calcular o n√∫mero de condi√ß√£o.")
    except Exception as e:
         st.error(f"‚ùå Erro ao calcular n√∫mero de condi√ß√£o: {e}")


# --- Carregar Artefactos Treinados (Refatorado para retornar status e resultado) ---
@st.cache_resource
def load_pipeline_artefacts_safe():
    artefacts_path = 'artefacts/'
    preprocessor_path = os.path.join(artefacts_path, 'preprocessor.joblib')
    model_path = os.path.join(artefacts_path, 'best_model.joblib')
    original_cols_path = os.path.join(artefacts_path, 'original_input_columns.joblib')
    processed_cols_path = os.path.join(artefacts_path, 'processed_feature_names.joblib')

    try:
        preprocessor = joblib.load(preprocessor_path)
        model = joblib.load(model_path)
        original_cols = joblib.load(original_cols_path)
        processed_cols = joblib.load(processed_cols_path)

        st.success("‚úÖ Artefactos do pipeline (pr√©-processador, modelo e nomes de colunas) carregados com sucesso!")
        return True, (preprocessor, model, original_cols, processed_cols)

    except FileNotFoundError as e:
        error_msg = f"‚ùå Erro ao carregar artefactos essenciais: {e}. Certifique-se de que todos os ficheiros .joblib est√£o na pasta '{artefacts_path}' e t√™m os nomes corretos."
        return False, error_msg
    except Exception as e:
        error_msg = f"‚ùå Ocorreu um erro inesperado ao carregar artefactos: {e}"
        return False, error_msg

# --- Chamar a fun√ß√£o de carregamento e verificar o resultado ---
success_artefacts, loaded_artefacts_result = load_pipeline_artefacts_safe()

if not success_artefacts:
    st.error(loaded_artefacts_result)
    st.stop()
else:
    preprocessor, model, original_cols, processed_cols = loaded_artefacts_result


# --- Carregar o seu Dataset Original para EDA ---
@st.cache_data
def load_student_data():
    data_path = 'student-data.csv'
    try:
        df = pd.read_csv(data_path)
        st.success(f"‚úÖ Dataset '{data_path}' carregado com sucesso ({df.shape[0]} linhas, {df.shape[1]} colunas).")
        return df
    except FileNotFoundError:
        st.error(f"‚ùå Erro: O ficheiro '{data_path}' n√£o foi encontrado. Certifique-se de que o dataset est√° no local correto.")
        st.stop()
    except Exception as e:
        st.error(f"‚ùå Ocorreu um erro ao carregar o dataset: {e}")
        st.stop()

# Carregar o dataset original
student_df_original = load_student_data()

# Identificar a coluna alvo original
TARGET_ORIGINAL_NAME = 'passed'
if TARGET_ORIGINAL_NAME not in student_df_original.columns:
    st.error(f"‚ùå Coluna alvo original '{TARGET_ORIGINAL_NAME}' n√£o encontrada no dataset. A aplica√ß√£o pode n√£o funcionar corretamente.")
    # st.stop() # Opcional: Parar se a coluna alvo n√£o existir

# Definir os nomes das classes para a sa√≠da da previs√£o e avalia√ß√£o
CLASS_NAMES = ['no', 'yes']

# Definir o nome da coluna alvo AP√ìS o mapeamento (usado no teste processado)
TARGET_PROCESSED_NAME = 'passed_mapped'


# --- Fun√ß√£o para carregar os conjuntos de dados processados (treino e teste) ---
@st.cache_data
def load_processed_data(target_col_name):
    processed_train_path = 'data/processed/train_processed.csv'
    processed_test_path = 'data/processed/test_processed.csv'

    train_df_processed = None
    test_df_processed = None
    errors = []

    try:
        train_df_processed = pd.read_csv(processed_train_path)
        if target_col_name not in train_df_processed.columns:
             errors.append(f"‚ùå Erro: A coluna alvo processada '{target_col_name}' n√£o foi encontrada no ficheiro '{processed_train_path}'.")
             train_df_processed = None
        else:
             st.success(f"‚úÖ Conjunto de treino processado carregado ({train_df_processed.shape[0]} linhas).")
    except FileNotFoundError:
        errors.append(f"‚ö†Ô∏è Ficheiro de treino processado '{processed_train_path}' n√£o encontrado. Algumas funcionalidades podem estar limitadas.")
    except Exception as e:
        errors.append(f"‚ùå Ocorreu um erro ao carregar o conjunto de treino processado: {e}")
        train_df_processed = None


    try:
        test_df_processed = pd.read_csv(processed_test_path)
        if target_col_name not in test_df_processed.columns:
             errors.append(f"‚ùå Erro: A coluna alvo processada '{target_col_name}' n√£o foi encontrada no ficheiro '{processed_test_path}'.")
             test_df_processed = None
        else:
             st.success(f"‚úÖ Conjunto de teste processado carregado ({test_df_processed.shape[0]} linhas).")
    except FileNotFoundError:
        errors.append(f"‚ö†Ô∏è Ficheiro de teste processado '{processed_test_path}' n√£o encontrado. Algumas funcionalidades podem estar limitadas.")
    except Exception as e:
        errors.error(f"‚ùå Ocorreu um erro ao carregar o conjunto de teste processado: {e}")
        test_df_processed = None

    for err in errors:
        st.markdown(err)

    return train_df_processed, test_df_processed

# Carregar os conjuntos de treino e teste processados
train_df_processed_global, test_df_processed_global = load_processed_data(TARGET_PROCESSED_NAME)


# --- Lista de modelos dispon√≠veis para a sec√ß√£o "An√°lise de Matriz" ---
AVAILABLE_MODELS_FOR_ANALYSIS = {
    "Regress√£o Log√≠stica": LogisticRegression(random_state=42, max_iter=1000),
    "KNN": KNeighborsClassifier(),
    "√Årvore de Decis√£o": DecisionTreeClassifier(random_state=42),
    "Random Forest": RandomForestClassifier(random_state=42),
    "SVM (Kernel RBF)": SVC(probability=True, random_state=42),
    "Gradient Boosting": GradientBoostingClassifier(random_state=42),
    "AdaBoost": AdaBoostClassifier(random_state=42)
}


# --- Sidebar para navega√ß√£o ---
with st.sidebar:
    # --- Adicionar espa√ßo para o Logotipo ---
    # Para adicionar o seu logotipo:
    # 1. Coloque o ficheiro da imagem (ex: logo.png) na mesma pasta do seu script Streamlit
    #    ou numa subpasta (ex: assets/logo.png).
    # 2. Descomente a linha abaixo que come√ßa com 'st.image('.
    # 3. Substitua '"caminho/para/o/seu/logotipo.png"' pelo caminho real do seu ficheiro.
    # 4. Ajuste o par√¢metro 'width' conforme necess√°rio para o tamanho desejado.
    # st.image("caminho/para/o/seu/logotipo.png", width=250) # <-- COLOQUE O CAMINHO DA IMAGEM AQUI

    st.markdown('<h1 class="sub-header" style="text-align: center;">Sistema de Interven√ß√£o Estudantil</h1>', unsafe_allow_html=True)

    menu = option_menu(
        menu_title=None,
        options=["In√≠cio", "Explora√ß√£o de Dados", "Previs√£o Individual", "An√°lise do Modelo Treinado", "An√°lise de Matriz", "Documenta√ß√£o"],
        icons=["house-door", "bar-chart-line", "clipboard-data", "robot", "grid-3x3", "book"],
        menu_icon="cast",
        default_index=0,
    )

    st.markdown("---")
    st.markdown("### Sobre a Aplica√ß√£o")
    st.info("""
    Ferramenta interativa para explorar o dataset estudantil, fazer previs√µes
    individuais e analisar o modelo de Machine Learning treinado e suas propriedades.
    """)

    # --- Adicionar Nomes dos Autores/Alunos e Orientador ---
    st.markdown("---")
    st.markdown("### Projeto Acad√©mico")
    st.write("Desenvolvido por:")
    st.write("- Afonso Marcos")
    st.write("- Afonso Salgado")
    st.write("- Pedro Afonso")
    st.write("---") # Separador opcional
    st.write("Orientador:")
    st.write("- [Nome do Orientador]") # <--- SUBSTITUIR PELO NOME REAL DO ORIENTADOR

    st.markdown("---")
    st.markdown("### Detalhes T√©cnicos") # Rebatizei para evitar conflito com 'Projeto Acad√©mico'
    st.write("Framework: Streamlit")
    st.write("Linguagem: Python")
    st.write("Bibliotecas: scikit-learn, pandas, numpy, plotly, joblib")


# --- Conte√∫do Principal ---

if menu == "In√≠cio":
    st.markdown('<h1 class="main-header">Bem-vindo ao Sistema de Interven√ß√£o Estudantil üöÄ</h1>', unsafe_allow_html=True)

    st.markdown('<p class="info-text">Este aplicativo √© uma ferramenta interativa baseada no seu modelo de Machine Learning para prever o desempenho estudantil, usando o dataset "UCI Student Performance".</p>', unsafe_allow_html=True)

    col1, col2, col3 = st.columns(3)

    with col1:
        st.markdown('<div class="metric-card">', unsafe_allow_html=True)
        st.metric("Amostras no Dataset", f"{student_df_original.shape[0]}")
        st.markdown('</div>', unsafe_allow_html=True)

    with col2:
        st.markdown('<div class="metric-card">', unsafe_allow_html=True)
        if 'original_cols' in locals() and original_cols is not None:
             st.metric("Caracter√≠sticas Originais", f"{len(original_cols)}")
        else:
             st.metric("Caracter√≠sticas Originais", "N/A")
        st.markdown('</div>', unsafe_allow_html=True)

    with col3:
        st.markdown('<div class="metric-card">', unsafe_allow_html=True)
        st.metric("Status do Pipeline", "Carregado ‚úÖ")
        st.markdown('</div>', unsafe_allow_html=True)

    st.markdown('<h2 class="sub-header">Funcionalidades:</h2>', unsafe_allow_html=True)

    st.markdown("""
    *   **Explora√ß√£o de Dados:** Visualize resumos, distribui√ß√µes e correla√ß√µes do dataset original, com foco na interpretabilidade.
    *   **Previs√£o Individual:** Insira dados de um aluno e obtenha uma previs√£o do seu desempenho final usando o modelo treinado.
    *   **An√°lise do Modelo Treinado:** Veja as m√©tricas de avalia√ß√£o e a matriz de confus√£o do modelo carregado no conjunto de teste.
    *   **An√°lise de Matriz:** Explore visualmente e analiticamente propriedades de matrizes relevantes (Confus√£o de *qualquer* modelo, Correla√ß√£o/Covari√¢ncia dos seus dados, Matriz Personalizada).
    *   **Documenta√ß√£o:** Encontre mais informa√ß√µes sobre a aplica√ß√£o e o projeto.
    """)


# --- Explora√ß√£o de Dados ---
elif menu == "Explora√ß√£o de Dados":
    st.markdown('<h1 class="main-header">Explora√ß√£o do Dataset Estudantil</h1>', unsafe_allow_html=True)

    df = student_df_original.copy() # Use uma c√≥pia para n√£o modificar o dataset cacheado

    st.markdown('<p class="info-text">Analise a estrutura, distribui√ß√£o e rela√ß√µes entre as caracter√≠sticas do seu dataset de dados estudantis (`student-data.csv`).</p>', unsafe_allow_html=True)

    tab1, tab2, tab3 = st.tabs(["üìã Resumo Geral", "üìà Distribui√ß√µes", "üîç Rela√ß√µes"])

    with tab1:
        st.markdown('<h2 class="sub-header">Resumo Geral do Dataset</h2>', unsafe_allow_html=True)

        col1, col2 = st.columns(2)

        with col1:
            st.write("**Dimens√µes do Dataset:**", df.shape)
            if 'original_cols' in locals() and original_cols is not None:
                 st.write(f"**Caracter√≠sticas (Features):** {len(original_cols)}")
            else:
                 st.warning("Nomes das caracter√≠sticas originais n√£o carregados.")
                 st.write(f"**Caracter√≠sticas (Features):** {df.shape[1] - (1 if TARGET_ORIGINAL_NAME in df.columns else 0)}")

            st.write(f"**Amostras:** {df.shape[0]}")

            if TARGET_ORIGINAL_NAME in df.columns:
                 st.write(f"**Vari√°vel Alvo:** '{TARGET_ORIGINAL_NAME}'")
                 unique_target_values = df[TARGET_ORIGINAL_NAME].dropna().unique().tolist() # Tratar NaNs
                 st.write(f"**Classes:** {', '.join(map(str, unique_target_values))}")

            st.markdown('---')
            st.write("**Primeiras 5 Linhas:**")
            st.dataframe(df.head(), use_container_width=True)

        with col2:
             if TARGET_ORIGINAL_NAME in df.columns:
                 st.write(f"**Distribui√ß√£o da Coluna '{TARGET_ORIGINAL_NAME}':**")
                 class_counts = df[TARGET_ORIGINAL_NAME].value_counts().reset_index()
                 class_counts.columns = ['Class', 'Count']
                 fig_pie = px.pie(
                     values=class_counts['Count'],
                     names=class_counts['Class'],
                     title=f"Distribui√ß√£o de '{TARGET_ORIGINAL_NAME}'",
                     hole=0.3,
                     color=class_counts['Class'], # Cor por classe
                     color_discrete_map={CLASS_NAMES[0]: 'salmon', CLASS_NAMES[1]: 'lightgreen'} # Cores para 'no' e 'yes'
                 )
                 fig_pie.update_layout(legend_title_text=TARGET_ORIGINAL_NAME.replace('_', ' ').title())
                 st.plotly_chart(fig_pie, use_container_width=True)
             else:
                  st.info(f"N√£o √© poss√≠vel mostrar a distribui√ß√£o da coluna alvo '{TARGET_ORIGINAL_NAME}'.")

        st.markdown('<h2 class="sub-header">Estat√≠sticas Descritivas</h2>', unsafe_allow_html=True)
        st.dataframe(df.describe(include='all'), use_container_width=True)

    with tab2:
        st.markdown('<h2 class="sub-header">Distribui√ß√£o das Caracter√≠sticas</h2>', unsafe_allow_html=True)
        st.markdown('<p class="info-text">Visualize a distribui√ß√£o de cada caracter√≠stica ou compare-a com a situa√ß√£o final do aluno.</p>', unsafe_allow_html=True)

        feature_options_dist = original_cols if 'original_cols' in locals() and original_cols is not None else df.columns.tolist()
        # Remover a coluna alvo da lista de op√ß√µes para distribui√ß√£o da feature
        if TARGET_ORIGINAL_NAME in feature_options_dist:
             feature_options_dist.remove(TARGET_ORIGINAL_NAME)

        selected_feature_dist = st.selectbox(
            "Selecione uma caracter√≠stica para visualizar a distribui√ß√£o:",
            options=feature_options_dist
        )

        if selected_feature_dist:
             dtype = df[selected_feature_dist].dtype

             # Adiciona um r√°dio bot√£o para escolher o tipo de visualiza√ß√£o
             view_option = st.radio(
                 f"Visualizar a distribui√ß√£o de '{selected_feature_dist.replace('_', ' ').title()}'",
                 ["Distribui√ß√£o Geral", f"Comparar com '{TARGET_ORIGINAL_NAME.replace('_', ' ').title()}'"],
                 horizontal=True,
                 key=f"view_option_{selected_feature_dist}" # Usa uma chave √∫nica para o widget
             )

             if view_option == "Distribui√ß√£o Geral":
                 # --- L√≥gica para Distribui√ß√£o Geral (Existente, Ligeiramente Melhorada) ---
                 if selected_feature_dist in ordinal_numeric_features_to_map:
                     st.write(f"Distribui√ß√£o Geral de **{selected_feature_dist.replace('_', ' ').title()}** (Interpretado com R√≥tulos):")
                     mapping_dict = ORDINAL_MAPPINGS[selected_feature_dist]

                     # Ensure NaNs are handled before mapping if necessary
                     temp_series_mapped = df[selected_feature_dist].dropna().map(mapping_dict)

                     counts_df = temp_series_mapped.value_counts().reset_index()
                     counts_df.columns = ['Label', 'Count']

                     ordered_labels = [mapping_dict.get(k) for k in sorted(mapping_dict.keys()) if mapping_dict.get(k) in counts_df['Label'].tolist()]

                     fig_bar = px.bar(
                         counts_df,
                         x='Label',
                         y='Count',
                         title=f'Distribui√ß√£o Geral de "{selected_feature_dist.replace("_", " ").title()}"',
                         text_auto=True # Mostrar valores nas barras
                     )
                     st.plotly_chart(fig_bar, use_container_width=True)
                     st.info(f"Este gr√°fico mostra quantos alunos caem em cada n√≠vel de '{selected_feature_dist.replace('_', ' ').title()}'.")

                 elif dtype in [np.number, 'int64', 'float64']: # Num√©ricas cont√≠nuas ou count
                      st.write(f"Distribui√ß√£o Geral de **{selected_feature_dist.replace('_', ' ').title()}**:")
                      fig_hist = px.histogram(
                          df.dropna(subset=[selected_feature_dist]), # Remover NaNs para o histograma
                          x=selected_feature_dist,
                          marginal="box",
                          title=f'Distribui√ß√£o Geral de "{selected_feature_dist.replace("_", " ").title()}"'
                      )
                      st.plotly_chart(fig_hist, use_container_width=True)
                      st.info(f"Este gr√°fico mostra a frequ√™ncia dos valores de '{selected_feature_dist.replace('_', ' ').title()}' (histograma) e um resumo da distribui√ß√£o (box plot).")


                 elif dtype == 'object' or pd.api.types.is_categorical_dtype(df[selected_feature_dist]): # Categ√≥ricas string/object
                      st.write(f"Distribui√ß√£o Geral de **{selected_feature_dist.replace('_', ' ').title()}**:")
                      counts_df = df[selected_feature_dist].value_counts().reset_index()
                      counts_df.columns = [selected_feature_dist, 'Count']
                      fig_bar = px.bar(
                          counts_df,
                          x=selected_feature_dist,
                          y='Count',
                          title=f'Distribui√ß√£o Geral de "{selected_feature_dist.replace("_", " ").title()}"',
                          text_auto=True
                      )
                      st.plotly_chart(fig_bar, use_container_width=True)
                      st.info(f"Este gr√°fico mostra quantos alunos pertencem a cada categoria de '{selected_feature_dist.replace('_', ' ').title()}'.")

                 else:
                     st.info(f"A caracter√≠stica '{selected_feature_dist}' tem um tipo de dado ({dtype}) que n√£o √© suportado para visualiza√ß√£o de distribui√ß√£o geral neste momento.")

             elif view_option == f"Comparar com '{TARGET_ORIGINAL_NAME.replace('_', ' ').title()}'":
                 # --- L√≥gica para Compara√ß√£o com a Vari√°vel Alvo ---
                 if TARGET_ORIGINAL_NAME not in df.columns:
                      st.warning(f"Coluna alvo '{TARGET_ORIGINAL_NAME}' n√£o encontrada no seu dataset para compara√ß√£o.")
                 else:
                    st.write(f"Compara√ß√£o da Distribui√ß√£o de **{selected_feature_dist.replace('_', ' ').title()}** por **{TARGET_ORIGINAL_NAME.replace('_', ' ').title()}**:")

                    # Certifica-se de que a coluna alvo tem apenas os valores esperados
                    if not set(df[TARGET_ORIGINAL_NAME].dropna().unique()).issubset(set(CLASS_NAMES)):
                         st.warning(f"A coluna alvo '{TARGET_ORIGINAL_NAME}' cont√©m valores inesperados ({df[TARGET_ORIGINAL_NAME].dropna().unique().tolist()}). A compara√ß√£o pode n√£o ser exibida corretamente.")
                         # Tenta continuar, mas pode falhar nos gr√°ficos


                    if selected_feature_dist in ordinal_numeric_features_to_map:
                         # Compara√ß√£o para Ordinais Num√©ricas Mapeadas
                         mapping_dict = ORDINAL_MAPPINGS[selected_feature_dist]

                         # Criar coluna mapeada TEMPOR√ÅRIA para o gr√°fico de compara√ß√£o
                         # Remover NaNs tanto da feature quanto da coluna alvo
                         temp_df_mapped = df.dropna(subset=[selected_feature_dist, TARGET_ORIGINAL_NAME]).copy()
                         temp_df_mapped['Feature_Label'] = temp_df_mapped[selected_feature_dist].map(mapping_dict)

                         # Contar por R√≥tulo da Feature e Classe Alvo
                         comparison_counts = temp_df_mapped.groupby(['Feature_Label', TARGET_ORIGINAL_NAME]).size().reset_index(name='Count')

                         # Garantir que TODOS os r√≥tulos poss√≠veis da feature mapeada estejam presentes, mesmo com Count=0, para a ordem correta
                         # Cria um multi-√≠ndice com todos os r√≥tulos da feature e todas as classes alvo
                         all_labels = [mapping_dict.get(k) for k in sorted(mapping_dict.keys())]
                         multi_index = pd.MultiIndex.from_product([all_labels, CLASS_NAMES], names=['Feature_Label', TARGET_ORIGINAL_NAME])

                         # Re-indexa o DataFrame de contagem e preenche NaNs com 0
                         comparison_counts = comparison_counts.set_index(['Feature_Label', TARGET_ORIGINAL_NAME]).reindex(multi_index, fill_value=0).reset_index()

                         # Garantir a ordem correta no eixo X (usa os r√≥tulos mapeados em ordem, agora todos presentes)
                         ordered_labels = [mapping_dict.get(k) for k in sorted(mapping_dict.keys())]


                         fig_comp_bar = px.bar(
                             comparison_counts,
                             x='Feature_Label',
                             y='Count',
                             color=TARGET_ORIGINAL_NAME, # Cor por Passou/N√£o Passou
                             title=f'Distribui√ß√£o de "{selected_feature_dist.replace("_", " ").title()}" por "{TARGET_ORIGINAL_NAME.replace("_", " ").title()}"',
                             # text_auto=True, # Auto text pode ficar confuso com muitas barras
                             barmode='group', # barras lado a lado
                             color_discrete_map={CLASS_NAMES[0]: 'salmon', CLASS_NAMES[1]: 'lightgreen'}
                         )
                         fig_comp_bar.update_layout(legend_title_text=TARGET_ORIGINAL_NAME.replace('_', ' ').title())
                         st.plotly_chart(fig_comp_bar, use_container_width=True)
                         st.info(f"""
                         Este gr√°fico compara o n√∫mero de alunos que passaram ('yes') e n√£o passaram ('no') em cada n√≠vel de '{selected_feature_dist.replace('_', ' ').title()}'.
                         Procure por n√≠veis onde h√° uma propor√ß√£o significativamente maior de barras verdes ('yes'). Isso sugere que este n√≠vel da caracter√≠stica est√° associado a uma maior probabilidade de aprova√ß√£o.
                         """)

                    elif dtype in [np.number, 'int64', 'float64']:
                         # Compara√ß√£o para Num√©ricas (Box Plot)
                         fig_comp_box = px.box(
                             df.dropna(subset=[selected_feature_dist, TARGET_ORIGINAL_NAME]), # Remover NaNs
                             x=TARGET_ORIGINAL_NAME,
                             y=selected_feature_dist,
                             title=f'Distribui√ß√£o de "{selected_feature_dist.replace("_", " ").title()}" por "{TARGET_ORIGINAL_NAME.replace("_", " ").title()}"',
                             color=TARGET_ORIGINAL_NAME, # Cor por Passou/N√£o Passou
                             color_discrete_map={CLASS_NAMES[0]: 'salmon', CLASS_NAMES[1]: 'lightgreen'},
                             points="all" # Mostrar todos os pontos
                         )
                         st.plotly_chart(fig_comp_box, use_container_width=True)
                         st.info(f"""
                         Este gr√°fico mostra a distribui√ß√£o dos valores de '{selected_feature_dist.replace('_', ' ').title()}' para alunos que passaram ('yes') e n√£o passaram ('no').
                         *   A linha no meio da caixa √© a mediana (valor t√≠pico).
                         *   A caixa representa 50% dos dados (entre o 1¬∫ e o 3¬∫ quartil).
                         *   Os "bigodes" estendem-se aos valores m√≠nimo e m√°ximo (excluindo outliers).
                         Observe se a mediana ou o intervalo de valores s√£o significativamente diferentes entre os grupos 'yes' e 'no'. Isso sugere que a caracter√≠stica √© importante para diferenciar entre alunos que passam e n√£o passam.
                         """)


                    elif dtype == 'object' or pd.api.types.is_categorical_dtype(df[selected_feature_dist]):
                         # Compara√ß√£o para Categ√≥ricas String/Object
                         # Contar por Categoria da Feature e Classe Alvo
                         comparison_counts = df.dropna(subset=[selected_feature_dist, TARGET_ORIGINAL_NAME]).groupby([selected_feature_dist, TARGET_ORIGINAL_NAME]).size().reset_index(name='Count')

                         # Opcional: garantir que TODAS as categorias da feature original estejam presentes, mesmo com Count=0
                         # Se a feature tiver muitas categorias, pode poluir o gr√°fico.
                         # Por enquanto, mantemos apenas as que aparecem nos dados ap√≥s dropna.

                         fig_comp_bar = px.bar(
                             comparison_counts,
                             x=selected_feature_dist,
                             y='Count',
                             color=TARGET_ORIGINAL_NAME, # Cor por Passou/N√£o Passou
                             title=f'Distribui√ß√£o de "{selected_feature_dist.replace("_", " ").title()}" por "{TARGET_ORIGINAL_NAME.replace("_", " ").title()}"',
                             text_auto=True,
                             barmode='group', # barras lado a lado
                             color_discrete_map={CLASS_NAMES[0]: 'salmon', CLASS_NAMES[1]: 'lightgreen'}
                         )
                         fig_comp_bar.update_layout(legend_title_text=TARGET_ORIGINAL_NAME.replace('_', ' ').title())
                         st.plotly_chart(fig_comp_bar, use_container_width=True)
                         st.info(f"""
                         Este gr√°fico compara o n√∫mero de alunos que passaram ('yes') e n√£o passaram ('no') em cada categoria de '{selected_feature_dist.replace('_', ' ').title()}'.
                         Procure por categorias onde h√° uma propor√ß√£o significativamente maior de barras verdes ('yes'). Isso sugere que essa categoria est√° associada a uma maior probabilidade de aprova√ß√£o.
                         """)

                    else:
                        st.info(f"A caracter√≠stica '{selected_feature_dist}' tem um tipo de dado ({dtype}) que n√£o √© suportado para compara√ß√£o com a situa√ß√£o final neste momento.")

    
    with tab3: # Esta √© a tab para "Rela√ß√µes", dentro de "Explora√ß√£o de Dados"
        st.markdown('<h2 class="sub-header">Rela√ß√µes entre Caracter√≠sticas</h2>', unsafe_allow_html=True)
        st.markdown('<p class="info-text">Analise a rela√ß√£o entre pares de caracter√≠sticas no seu dataset, coloridas pela classe alvo.</p>', unsafe_allow_html=True)

        # Certifica-se de que usa o DataFrame 'df' da EDA, que √© uma c√≥pia do original
        df_source = df # df √© a c√≥pia do dataset original criada no in√≠cio desta sec√ß√£o EDA

        # Verifica se a coluna alvo existe
        if TARGET_ORIGINAL_NAME not in df_source.columns:
            st.warning(f"Coluna alvo '{TARGET_ORIGINAL_NAME}' n√£o encontrada no seu dataset. As visualiza√ß√µes de rela√ß√£o coloridas pela situa√ß√£o final n√£o estar√£o dispon√≠veis.")
            # Adiciona uma an√°lise b√°sica de correla√ß√£o para features num√©ricas se a alvo estiver faltando
            st.markdown('### Matriz de Correla√ß√£o (Sem cor por Classe)', unsafe_allow_html=True)
            df_features_only = df_source[original_cols] if 'original_cols' in locals() and original_cols is not None else df_source
            df_numeric_for_corr = df_features_only.select_dtypes(include=np.number)
            if df_numeric_for_corr.empty:
                st.info("N√£o h√° colunas num√©ricas para calcular a matriz de correla√ß√£o.")
            else:
                 fig_corr, corr_matrix = plot_correlation_matrix_px(df_numeric_for_corr) # Assume plot_correlation_matrix_px is globally defined
                 if fig_corr is not None:
                      st.plotly_chart(fig_corr, use_container_width=True)
            pass # Sai do bloco tab3 se a coluna alvo n√£o existir


        # --- Se a coluna alvo existir, continua com as visualiza√ß√µes coloridas ---

        st.markdown('### Visualiza√ß√£o de Rela√ß√µes por Situa√ß√£o Final', unsafe_allow_html=True)
        st.markdown(f'<p class="info-text">Selecione duas caracter√≠sticas para visualizar sua rela√ß√£o e como a "{TARGET_ORIGINAL_NAME.replace("_", " ").title()}" se distribui.</p>', unsafe_allow_html=True)


        # Obter a lista de todas as features para sele√ß√£o (exceto a alvo)
        all_features_options = original_cols if 'original_cols' in locals() and original_cols is not None else df_source.columns.tolist()
        if TARGET_ORIGINAL_NAME in all_features_options:
            all_features_options.remove(TARGET_ORIGINAL_NAME)


        # Controles para selecionar as duas features
        col_select1, col_select2 = st.columns(2)
        with col_select1:
            feature1 = st.selectbox("Selecione a Caracter√≠stica 1", all_features_options, index=0, key="rel_feature1")
        with col_select2:
            # Excluir a Caracter√≠stica 1 da lista de op√ß√µes para a Caracter√≠stica 2
            options_feature2 = [col for col in all_features_options if col != feature1]
            # Encontrar um √≠ndice padr√£o seguro para feature2
            default_index_feature2 = 0
            # Tenta encontrar um default razo√°vel que n√£o seja igual a feature1
            if feature1 == all_features_options[0] and len(options_feature2) > 0:
                 if len(all_features_options) > 1:
                      # Tenta selecionar a segunda feature original como default para a segunda caixa
                      second_original_feature = all_features_options[1]
                      if second_original_feature in options_feature2:
                           default_index_feature2 = options_feature2.index(second_original_feature)

            feature2 = st.selectbox("Selecione a Caracter√≠stica 2", options_feature2, index=default_index_feature2, key="rel_feature2")


        if feature1 and feature2:
            # Determine os tipos das features selecionadas (num√©rica, categ√≥rica/ordinal)
            dtype1 = df_source[feature1].dtype
            dtype2 = df_source[feature2].dtype

            is_numeric1 = pd.api.types.is_numeric_dtype(dtype1) and feature1 not in ordinal_numeric_features_to_map # Trata ordinais num√©ricas como categ√≥ricas para plotagem espec√≠fica
            is_numeric2 = pd.api.types.is_numeric_dtype(dtype2) and feature2 not in ordinal_numeric_features_to_map

            is_ordinal_or_categorical1 = (feature1 in ordinal_numeric_features_to_map) or (dtype1 == 'object') or pd.api.types.is_categorical_dtype(dtype1)
            is_ordinal_or_categorical2 = (feature2 in ordinal_numeric_features_to_map) or (dtype2 == 'object') or pd.api.types.is_categorical_dtype(dtype2)


            # --- Plotagem baseada nos tipos de features ---

            # Caso 1: Ambas s√£o num√©ricas (cont√≠nuas)
            if is_numeric1 and is_numeric2:
                st.write(f"#### Dispers√£o: {feature1.replace('_', ' ').title()} vs {feature2.replace('_', ' ').title()} por {TARGET_ORIGINAL_NAME.replace('_', ' ').title()}")
                st.info("Este gr√°fico mostra a rela√ß√£o entre duas caracter√≠sticas num√©ricas cont√≠nuas, colorida pela situa√ß√£o final. Pontos pr√≥ximos podem indicar grupos de alunos com caracter√≠sticas semelhantes.")
                fig = px.scatter(
                    df_source,
                    x=feature1,
                    y=feature2,
                    color=TARGET_ORIGINAL_NAME,
                    labels={"color": TARGET_ORIGINAL_NAME.replace('_', ' ').title()},
                    title=f"Dispers√£o: {feature1.replace('_', ' ').title()} vs {feature2.replace('_', ' ').title()}",
                    opacity=0.7,
                    hover_data={TARGET_ORIGINAL_NAME:False, feature1:True, feature2:True} # Exibe nome e valor das features no hover
                )
                fig.update_layout(legend_title_text=TARGET_ORIGINAL_NAME.replace('_', ' ').title())
                st.plotly_chart(fig, use_container_width=True)

            # Caso 2: Uma num√©rica (cont√≠nua) e outra categ√≥rica/ordinal
            elif is_numeric1 and is_ordinal_or_categorical2:
                st.write(f"#### Distribui√ß√£o de {feature1.replace('_', ' ').title()} por {feature2.replace('_', ' ').title()} e {TARGET_ORIGINAL_NAME.replace('_', ' ').title()}")
                st.info(f"Este gr√°fico mostra a distribui√ß√£o de **{feature1.replace('_', ' ').title()}** (num√©rica) para cada n√≠vel de **{feature2.replace('_', ' ').title()}** (categ√≥rica/ordinal), separada por situa√ß√£o final.")

                # Mapear feature2 se for ordinal num√©rica para exibir r√≥tulos no gr√°fico
                df_plot = df_source.copy()
                if feature2 in ordinal_numeric_features_to_map:
                     df_plot[feature2] = df_plot[feature2].map(ORDINAL_MAPPINGS[feature2]).fillna('NaN') # Mapeia e trata NaNs
                     x_label_plot = feature2 # Nome da feature original
                     category_orders = {x_label_plot: [ORDINAL_MAPPINGS[feature2].get(k) for k in sorted(ORDINAL_MAPPINGS[feature2].keys())]} # Ordem correta para ordinais
                else:
                     x_label_plot = feature2
                     category_orders = None # Sem ordem espec√≠fica para categ√≥ricas nominais

                fig = px.box( # Ou px.violin
                    df_plot.dropna(subset=[feature1, feature2, TARGET_ORIGINAL_NAME]),
                    x=x_label_plot,
                    y=feature1,
                    color=TARGET_ORIGINAL_NAME,
                    labels={"color": TARGET_ORIGINAL_NAME.replace('_', ' ').title(), x_label_plot: feature2.replace('_', ' ').title()}, # R√≥tulos
                    title=f"Distribui√ß√£o de {feature1.replace('_', ' ').title()} por {feature2.replace('_', ' ').title()} e {TARGET_ORIGINAL_NAME.replace('_', ' ').title()}",
                    category_orders=category_orders,
                    # points="all" # Opcional: mostrar pontos individuais (pode sobrecarregar)
                )
                fig.update_layout(legend_title_text=TARGET_ORIGINAL_NAME.replace('_', ' ').title())
                st.plotly_chart(fig, use_container_width=True)

            elif is_ordinal_or_categorical1 and is_numeric2: # Sim√©trico ao caso anterior
                st.write(f"#### Distribui√ß√£o de {feature2.replace('_', ' ').title()} por {feature1.replace('_', ' ').title()} e {TARGET_ORIGINAL_NAME.replace('_', ' ').title()}")
                st.info(f"Este gr√°fico mostra a distribui√ß√£o de **{feature2.replace('_', ' ').title()}** (num√©rica) para cada n√≠vel de **{feature1.replace('_', ' ').title()}** (categ√≥rica/ordinal), separada por situa√ß√£o final.")

                # Mapear feature1 se for ordinal num√©rica
                df_plot = df_source.copy()
                if feature1 in ordinal_numeric_features_to_map:
                     df_plot[feature1] = df_plot[feature1].map(ORDINAL_MAPPINGS[feature1]).fillna('NaN')
                     x_label_plot = feature1
                     category_orders = {x_label_plot: [ORDINAL_MAPPINGS[feature1].get(k) for k in sorted(ORDINAL_MAPPINGS[feature1].keys())]}
                else:
                     x_label_plot = feature1
                     category_orders = None

                fig = px.box( # Ou px.violin
                    df_plot.dropna(subset=[feature1, feature2, TARGET_ORIGINAL_NAME]),
                    x=x_label_plot,
                    y=feature2,
                    color=TARGET_ORIGINAL_NAME,
                    labels={"color": TARGET_ORIGINAL_NAME.replace('_', ' ').title(), x_label_plot: feature1.replace('_', ' ').title()},
                    title=f"Distribui√ß√£o de {feature2.replace('_', ' ').title()} por {feature1.replace('_', ' ').title()} e {TARGET_ORIGINAL_NAME.replace('_', ' ').title()}",
                    category_orders=category_orders,
                    # points="all"
                )
                fig.update_layout(legend_title_text=TARGET_ORIGINAL_NAME.replace('_', ' ').title())
                st.plotly_chart(fig, use_container_width=True)

            # Caso 3: Ambas s√£o categ√≥ricas/ordinais
            elif is_ordinal_or_categorical1 and is_ordinal_or_categorical2:
                st.write(f"#### Contagem de Alunos por {feature1.replace('_', ' ').title()} vs {feature2.replace('_', ' ').title()} por {TARGET_ORIGINAL_NAME.replace('_', ' ').title()}")
                st.info(f"Este gr√°fico de barras agrupadas mostra o n√∫mero de alunos em cada combina√ß√£o de n√≠veis de **{feature1.replace('_', ' ').title()}** e **{feature2.replace('_', ' ').title()}**, separada por situa√ß√£o final.")

                # Mapear ambas as features se forem ordinais num√©ricas
                df_plot = df_source.copy()
                x_label_plot = feature1
                color_label_plot = feature2
                category_orders_dict = {} # Para controlar a ordem dos eixos

                if feature1 in ordinal_numeric_features_to_map:
                     df_plot[feature1] = df_plot[feature1].map(ORDINAL_MAPPINGS[feature1]).fillna('NaN')
                     category_orders_dict[feature1] = [ORDINAL_MAPPINGS[feature1].get(k) for k in sorted(ORDINAL_MAPPINGS[feature1].keys())] # Ordem correta para x
                if feature2 in ordinal_numeric_features_to_map:
                     df_plot[feature2] = df_plot[feature2].map(ORDINAL_MAPPINGS[feature2]).fillna('NaN')
                     category_orders_dict[feature2] = [ORDINAL_MAPPINGS[feature2].get(k) for k in sorted(ORDINAL_MAPPINGS[feature2].keys())] # Ordem correta para cor

                # Contar ocorr√™ncias por combina√ß√£o das 3 colunas
                counts_df = df_plot.dropna(subset=[feature1, feature2, TARGET_ORIGINAL_NAME]).groupby([feature1, feature2, TARGET_ORIGINAL_NAME]).size().reset_index(name='Count')

                # Garantir que todas as combina√ß√µes poss√≠veis estejam presentes para a ordem (pode ser complexo e n√£o essencial para plotly express)
                # Plotly express geralmente ordena automaticamente categ√≥ricas se n√£o houver category_orders

                fig = px.bar(
                    counts_df,
                    x=feature1,
                    y='Count',
                    color=feature2, # Colorir pela Caracter√≠stica 2
                    facet_col=TARGET_ORIGINAL_NAME, # Separar por Situa√ß√£o Final
                    facet_col_wrap=2, # Exibir 2 colunas de facetas
                    title=f"Contagem de Alunos por {feature1.replace('_', ' ').title()} vs {feature2.replace('_', ' ').title()} por {TARGET_ORIGINAL_NAME.replace('_', ' ').title()}",
                    category_orders=category_orders_dict, # Aplica as ordens se definidas
                    labels={TARGET_ORIGINAL_NAME: TARGET_ORIGINAL_NAME.replace('_', ' ').title()}, # Label da faceta
                    barmode='group' # barras agrupadas (uma barra para cada n√≠vel de feature2 dentro de cada n√≠vel de feature1)
                    # barmode='stack' # Opcional: barras empilhadas
                )

                # Ajustar t√≠tulos das facetas (opcional)
                fig.for_each_annotation(lambda a: a.update(text=f"{TARGET_ORIGINAL_NAME.replace('_', ' ').title()}={a.text.split('=')[-1]}"))

                fig.update_layout(legend_title_text=feature2.replace('_', ' ').title()) # T√≠tulo da legenda √© a Caracter√≠stica 2
                st.plotly_chart(fig, use_container_width=True)


            else:
                # Caso inesperado (e.g., colunas n√£o reconhecidas)
                st.info(f"N√£o foi poss√≠vel gerar uma visualiza√ß√£o apropriada para os tipos de dados selecionados ({dtype1} para {feature1}, {dtype2} para {feature2}).")

        else: # Caso feature1 ou feature2 sejam None (n√£o deveriam ser com os selectboxes populados)
             st.warning("Por favor, selecione duas caracter√≠sticas para visualizar a rela√ß√£o.")


        st.markdown("---") # Adiciona um separador visual antes da matriz de correla√ß√£o

        # --- Matriz de Correla√ß√£o (Mantida aqui, √© relevante para rela√ß√µes entre features) ---
        st.markdown('### Matriz de Correla√ß√£o', unsafe_allow_html=True)
        st.markdown('<p class="info-text">Veja a correla√ß√£o linear entre as caracter√≠sticas num√©ricas do seu dataset.</p>', unsafe_allow_html=True)

        # Certifica-se de que usa o DataFrame 'df' da EDA (df_source)
        # Para a matriz principal, ainda √© √∫til ver correla√ß√µes APENAS entre features
        df_features_only = df_source[original_cols] if 'original_cols' in locals() and original_cols is not None else df_source.drop(columns=[TARGET_ORIGINAL_NAME] if TARGET_ORIGINAL_NAME in df_source.columns else [])
        df_numeric_for_corr_matrix = df_features_only.select_dtypes(include=np.number)

        if df_numeric_for_corr_matrix.empty:
             st.info("N√£o h√° colunas num√©ricas entre as caracter√≠sticas usadas para calcular a matriz de correla√ß√£o no seu dataset.")
        else:
            # A fun√ß√£o plot_correlation_matrix_px precisa estar definida em outro lugar
            fig_corr, corr_matrix = plot_correlation_matrix_px(df_numeric_for_corr_matrix) # Usa o df sem a target para a matriz principal
            if fig_corr is not None and corr_matrix is not None:
                st.plotly_chart(fig_corr, use_container_width=True)

                # REMOVER: Se√ß√£o Pares com Alta Correla√ß√£o entre features
                # st.markdown('#### Pares com Alta Correla√ß√£o', unsafe_allow_html=True)
                # st.markdown('<p class="info-text">Identifica pares de caracter√≠sticas com forte correla√ß√£o linear (|r| > 0.7).</p>', unsafe_allow_html=True)
                # corr_unstacked = corr_matrix.stack().reset_index()
                # corr_unstacked.columns = ['Feature1', 'Feature2', 'Correlation']
                # high_corr_pairs = corr_unstacked[
                #     (abs(corr_unstacked['Correlation']) > 0.7) &
                #     (corr_unstacked['Feature1'] != corr_corr_pairs['Feature2'])
                # ].sort_values(by='Correlation', ascending=False)

                # # Remover duplicados (Feature1, Feature2) e (Feature2, Feature1)
                # high_corr_pairs['Pair'] = high_corr_pairs.apply(lambda row: tuple(sorted((row['Feature1'], row['Feature2']))), axis=1)
                # high_corr_pairs = high_corr_pairs.drop_duplicates(subset=['Pair']).drop(columns=['Pair'])

                # if not high_corr_pairs.empty:
                #     st.dataframe(high_corr_pairs.round(4), use_container_width=True)
                #     st.warning("‚ö†Ô∏è Alta correla√ß√£o entre algumas caracter√≠sticas pode indicar redund√¢ncia.")
                # else:
                #     st.info("N√£o foram encontrados pares de caracter√≠sticas com correla√ß√£o linear forte (|r| > 0.7) entre as caracter√≠sticas num√©ricas usadas.")

            else:
                 st.info("N√£o h√° dados num√©ricos suficientes entre as caracter√≠sticas originais no seu dataset para calcular a matriz de correla√ß√£o.")


        # --- Nova Se√ß√£o: Correla√ß√£o com a Vari√°vel Alvo "passed" ---
        st.markdown(f'### Correla√ß√£o com a Vari√°vel Alvo: "{TARGET_ORIGINAL_NAME}"', unsafe_allow_html=True)
        st.markdown(f'<p class="info-text">Veja a correla√ß√£o linear das caracter√≠sticas num√©ricas com a vari√°vel alvo "{TARGET_ORIGINAL_NAME}".</p>', unsafe_allow_html=True)

        # Prepara o DataFrame para calcular a correla√ß√£o com a target
        df_for_target_corr = None # Inicializa como None
        target_col_processed = None # Vai guardar a s√©rie da coluna target (original ou convertida)

        # Verifica se a coluna alvo existe
        if TARGET_ORIGINAL_NAME in df_source.columns:
            target_col_original = df_source[TARGET_ORIGINAL_NAME]

            # Verifica se a coluna alvo j√° √© num√©rica ou booleana (Pandas trata booleanos como 0/1 em ops num√©ricas)
            if pd.api.types.is_numeric_dtype(target_col_original) or pd.api.types.is_bool_dtype(target_col_original):
                st.info(f"A coluna alvo '{TARGET_ORIGINAL_NAME}' √© num√©rica/booleana. Calculando correla√ß√£o diretamente.")
                df_for_target_corr = df_source.select_dtypes(include=np.number).copy()
                # Garante que a coluna target est√° inclu√≠da se for num√©rica/booleana mas n√£o pega por select_dtypes (ex: bool)
                if TARGET_ORIGINAL_NAME not in df_for_target_corr.columns:
                     df_for_target_corr[TARGET_ORIGINAL_NAME] = target_col_original.astype(float) # Converte para float para consist√™ncia
                target_col_processed = df_for_target_corr[TARGET_ORIGINAL_NAME]


            # Se n√£o for num√©rica/booleana, tenta converter se for bin√°ria
            elif not pd.api.types.is_numeric_dtype(target_col_original) and not pd.api.types.is_bool_dtype(target_col_original):
                 unique_target_values = target_col_original.dropna().unique()
                 if len(unique_target_values) == 2:
                     st.warning(f"A coluna alvo '{TARGET_ORIGINAL_NAME}' n√£o √© num√©rica, mas parece ser bin√°ria ({unique_target_values[0]} vs {unique_target_values[1]}). Convertendo para 0/1 para calcular a correla√ß√£o linear (Ponto-Bisserial).")
                     df_for_target_corr = df_source.select_dtypes(include=np.number).copy()
                     # Converte os valores bin√°rios para 0 e 1. cat.codes mapeia categorias para inteiros.
                     target_col_processed = target_col_original.astype('category').cat.codes.astype(float) # Converte para float para consist√™ncia
                     df_for_target_corr[TARGET_ORIGINAL_NAME] = target_col_processed

                 else:
                     # N√£o √© num√©rica e n√£o √© bin√°ria
                     st.warning(f"A coluna alvo '{TARGET_ORIGINAL_NAME}' n√£o √© num√©rica e n√£o parece ser bin√°ria (mais de 2 valores √∫nicos n√£o-NaN: {len(unique_target_values)}). N√£o √© poss√≠vel calcular correla√ß√£o linear de Pearson com ela.")
                     df_for_target_corr = None # Define como None para pular o c√°lculo

            # Se chegou aqui e df_for_target_corr ainda √© None, significa que a coluna alvo n√£o √© adequada
            # Nada a fazer, a mensagem de warning j√° foi exibida.

        else:
             # A coluna alvo n√£o foi encontrada no DataFrame
             st.warning(f"A coluna alvo '{TARGET_ORIGINAL_NAME}' n√£o foi encontrada no DataFrame para calcular a correla√ß√£o.")
             df_for_target_corr = None # Define como None para pular o c√°lculo


        # --- C√°lculo e Exibi√ß√£o da Correla√ß√£o com a Target (se df_for_target_corr foi preparado) ---
        if df_for_target_corr is not None and TARGET_ORIGINAL_NAME in df_for_target_corr.columns:
             # Verifica se h√° outras colunas num√©ricas al√©m da target para correlacionar
             other_cols_for_corr = [col for col in df_for_target_corr.columns if col != TARGET_ORIGINAL_NAME]

             if not other_cols_for_corr:
                  st.info(f"N√£o h√° outras colunas num√©ricas no dataset para calcular a correla√ß√£o com '{TARGET_ORIGINAL_NAME}'.")
             else:
                # Calcula a matriz de correla√ß√£o usando o DataFrame preparado (com a target, potencialmente convertida)
                corr_matrix_with_target = df_for_target_corr.corr()

                # Extrai as correla√ß√µes com a coluna alvo
                if TARGET_ORIGINAL_NAME in corr_matrix_with_target.columns:
                     # Remove a correla√ß√£o da target com ela mesma (que √© 1)
                     target_correlations = corr_matrix_with_target[TARGET_ORIGINAL_NAME].drop(TARGET_ORIGINAL_NAME, errors='ignore') # errors='ignore' para seguran√ßa

                     # Classifica pela magnitude absoluta da correla√ß√£o (para ver as mais "relacionadas", positivas ou negativas)
                     if not target_correlations.empty:
                         sorted_target_corr_abs = target_correlations.abs().sort_values(ascending=False)

                         # Prepara o DataFrame para exibi√ß√£o, mantendo o valor original da correla√ß√£o
                         # Garante que a ordem √© a da classifica√ß√£o por valor absoluto
                         ordered_target_correlations = target_correlations.loc[sorted_target_corr_abs.index]

                         corr_df = ordered_target_correlations.reset_index()
                         corr_df.columns = ['Feature', f'Correlation_with_{TARGET_ORIGINAL_NAME}']

                         st.dataframe(corr_df.round(4), use_container_width=True)
                         # Mensagem informativa ajustada
                         status_message = f"As caracter√≠sticas acima s√£o listadas pela for√ßa da correla√ß√£o linear com '{TARGET_ORIGINAL_NAME}' (do mais forte para o mais fraco)."
                         if pd.api.types.is_numeric_dtype(target_col_original) or pd.api.types.is_bool_dtype(target_col_original):
                              pass # J√° informado acima que √© num√©rica/booleana
                         else: # Implica que foi convertida de bin√°ria
                              status_message += f" (A coluna '{TARGET_ORIGINAL_NAME}' foi convertida para 0/1 para este c√°lculo)."
                         st.info(status_message)

                     else:
                         st.info(f"N√£o h√° outras colunas num√©ricas para calcular a correla√ß√£o com '{TARGET_ORIGINAL_NAME}'.")

                else:
                    st.warning(f"Erro interno: A coluna alvo '{TARGET_ORIGINAL_NAME}' n√£o foi encontrada na matriz de correla√ß√£o calculada ap√≥s o processamento.")

        # Se df_for_target_corr foi None (target n√£o encontrada ou n√£o bin√°ria), as mensagens de warning j√° foram exibidas.

elif menu == "Previs√£o Individual":
    st.markdown('<h2 class="sub-header">Dados do Aluno</h2>', unsafe_allow_html=True)
    st.markdown('<p class="info-text">Insira os dados de um aluno para prever se ele passar√° ou n√£o.</p>', unsafe_allow_html=True)

    if 'original_cols' not in locals() or original_cols is None:
        st.error("N√£o foi poss√≠vel carregar os nomes das caracter√≠sticas originais. A sec√ß√£o de Previs√£o Individual n√£o est√° dispon√≠vel.")
    else:
        input_data = {}

        original_dtypes = student_df_original[original_cols].dtypes

        numeric_features = [col for col in original_cols if original_dtypes[col] in [np.number, 'int64', 'float64']]
        categorical_features = [col for col in original_cols if original_dtypes[col] == 'object'] # Assumindo que categ√≥ricas s√£o object/string

        # --- Descri√ß√£o Curta das Caracter√≠sticas (Para a Previs√£o Individual) ---
        # √â recomendado que este dicion√°rio esteja definido globalmente para evitar repeti√ß√£o.
        # Se o seu dicion√°rio global √© mais completo, use esse em vez de redefini-lo aqui.
        # Exemplo de como deve ser (verificar o seu topo se j√° existe):
        feature_descriptions_short = {
            "school": "Escola", "sex": "G√™nero", "age": "Idade", "address": "Resid√™ncia",
            "famsize": "Tamanho fam√≠lia", "Pstatus": "Status pais", "Medu": "Escolaridade m√£e",
            "Fedu": "Escolaridade pai", "Mjob": "Ocupa√ß√£o m√£e", "Fjob": "Ocupa√ß√£o pai",
            "reason": "Motivo escola", "guardian": "Guardi√£o", "traveltime": "Tempo viagem",
            "studytime": "Tempo estudo", "failures": "Reprova√ß√µes", "schoolsup": "Apoio escola",
            "famsup": "Apoio fam√≠lia", "paid": "Aulas pagas", "activities": "Atividades extra",
            "nursery": "Frequentou creche", "higher": "Deseja superior", "internet": "Acesso internet",
            "romantic": "Relacionamento", "famrel": "Qualidade rela√ß√µes familiares", "freetime": "Tempo livre",
            "goout": "Sair c/amigos", "Dalc": "√Ålcool dias semana", "Walc": "√Ålcool fins semana",
            "health": "Estado sa√∫de", "absences": "Faltas", "passed": "Aprovado"
        }
        # Fim do Dicion√°rio Curto (Verifique se j√° existe no topo do script)


        # --- CSS para o Grid Layout e Descri√ß√£o Pequena ---
        # Este CSS DEVE estar definido no bloco <style> principal no topo do script.
        # Replicado aqui APENAS PARA REFER√äNCIA visual do que esta sec√ß√£o precisa de CSS.
        # N√ÉO MANTENHA ESTE BLOCO <style> DUPLICADO se j√° tiver o CSS globalmente.
        st.markdown("""
        <style>
            /* CSS para o Grid Layout na Previs√£o Individual */
            .input-grid-container {
                display: grid;
                grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
                gap: 20px;
                margin-bottom: 20px;
            }
            .grid-item { /* Alterado de grid_item para grid-item (padr√£o CSS) */
                display: flex;
                flex-direction: column;
            }
            .grid-item div[data-testid="stAlert"] { /* Alterado */
                margin-top: 5px; margin-bottom: 5px; padding: 10px;
                font-size: 0.9rem; line-height: 1.4;
            }
             .grid-item div[data-testid="stNumberInput"], /* Alterado */
             .grid-item div[data-testid="stSelectbox"] { /* Alterado */
                 margin-top: 5px;
             }
             .feature-label-container {
                 margin-bottom: 5px;
                 display: flex;
                 align-items: baseline;
                 flex-wrap: wrap;
             }
             .feature-label-container strong {
                  margin-right: 5px;
             }
             .small-description {
                 font-size: 0.8em;
                 font-weight: normal;
                 color: #555;
             }
             .grid-item strong { /* Alterado */
                 display: inline-block;
             }
        </style>
        """, unsafe_allow_html=True)
        # --- Fim CSS (Verifique se j√° est√° no topo do script) ---

        # --- Op√ß√£o para escolher o modelo ---
        st.markdown("### Sele√ß√£o do Modelo para Previs√£o")

        artefacts_path = 'artefacts/'
        selected_model_instance = None # Inicializa como None
        selected_model_filename = None # Inicializa como None

        try:
            # Lista todos os ficheiros .joblib na pasta 'artefacts'
            all_joblib_files = [f for f in os.listdir(artefacts_path) if f.endswith('.joblib')]

            # Filtra para obter apenas os ficheiros que s√£o modelos (exclui preprocessor, colunas)
            model_files = [f for f in all_joblib_files if f not in ['preprocessor.joblib', 'original_input_columns.joblib', 'processed_feature_names.joblib']]
            model_files.sort() # Ordena alfabeticamente para uma lista consistente

            # --- Dicion√°rio de mapeamento de NOME DE FICHEIRO para NOME DE EXIBI√á√ÉO ---
            # Voc√™ DEVE atualizar este dicion√°rio se salvar novos tipos de modelos com nomes diferentes.
            # A chave √© o nome do ficheiro .joblib (sem o caminho, apenas o nome).
            # O valor √© o nome amig√°vel que voc√™ quer que apare√ßa no selectbox.
            filename_to_display_name_map = {

                'DecisionTreeClassifier.joblib': '√Årvore de Decis√£o',
                'random_forest_model.joblib': 'Random Forest',
                'svm_model.joblib': 'SVM (SVC Padr√£o)',
                'svm_(otimizado)_model.joblib': 'SVM (SVC Otimizado)',
                  # Assumindo que seu SVC foi salvo como SVC.joblib
                # 'SVC_linear.joblib': 'SVM (Kernel Linear)', # Exemplo se salvou um SVM linear com nome diferente
                'random_forest_(otimizado)_model.joblib': 'Gradient Boosting',
                'best_model.joblib': 'AdaBoost(modelo recomendado)',
                # ADICIONE AQUI OUTROS NOMES DE FICHEIRO SEUS -> NOME AMIG√ÅVEL
                # Ex: 'MeuNovoModeloPersonalizado.joblib': 'Modelo Personalizado'
            }
            # --- Fim do dicion√°rio de mapeamento ---


            # Cria a lista de nomes a serem exibidos no selectbox e o mapeamento DE EXIBI√á√ÉO para FICHEIRO
            model_display_options = []
            model_filename_map = {} # Mapeia o nome exibido de volta para o nome do ficheiro .joblib
            default_model_display_name = 'AdaBoost(modelo recomendado)' # Nome de exibi√ß√£o do modelo padr√£o

            # --- ESTE √â O BLOCO CORRIGIDO PARA CRIAR A LISTA DE SELE√á√ÉO ---
            for f in model_files:
                # Obt√©m o nome amig√°vel do mapeamento, ou usa o nome do ficheiro (sem .joblib) como fallback
                display_name_base = filename_to_display_name_map.get(f, f[:-8]) # Remove .joblib do nome do ficheiro
                default_model_display_name = 'AdaBoost(modelo recomendado)'

                display_name = display_name_base # Come√ßa com o nome base
                # Adiciona o nome de exibi√ß√£o √† lista
                model_display_options.append(display_name)
                # Mapeia o nome de exibi√ß√£o de volta para o nome do ficheiro real .joblib
                model_filename_map[display_name] = f
            # --- FIM DO BLOCO CORRIGIDO PARA CRIAR A LISTA DE SELE√á√ÉO ---


            # Encontra o √≠ndice padr√£o na lista de exibi√ß√£o
            default_model_index = 0 # Default para o primeiro da lista se best_model n√£o estiver l√° ou lista vazia
            if default_model_display_name and default_model_display_name in model_display_options:
                 default_model_index = model_display_options.index(default_model_display_name)
            # N√£o precisamos de else, pois default_model_index j√° √© 0

            if len(model_display_options) > 0:
                 selected_display_name = st.selectbox(
                    "Escolha o modelo treinado para fazer a previs√£o:",
                    options=model_display_options,
                    index=default_model_index,
                    key="prediction_model_selector"
                 )

                 # Obt√©m o nome do ficheiro real a partir do nome de exibi√ß√£o selecionado
                 selected_model_filename = model_filename_map.get(selected_display_name)

                 # Carrega o modelo selecionado usando a fun√ß√£o load_specific_model
                 # ESTA FUN√á√ÉO load_specific_model DEVE ESTAR DEFINIDA ANTES DESTE BLOCO elif
                 # Assume que load_specific_model trata erros de ficheiro n√£o encontrado
                 if selected_model_filename: # S√≥ tenta carregar se obteve um nome de ficheiro v√°lido do mapeamento
                      selected_model_instance = load_specific_model(selected_model_filename)
                 else:
                      st.error(f"Erro interno: N√£o foi poss√≠vel mapear o nome selecionado '{selected_display_name}' para um ficheiro de modelo.")
                      selected_model_instance = None


                 # --- Exibe o tipo do MELHOR modelo (best_model.joblib) e a informa√ß√£o recomendada ---
                 # A vari√°vel 'model' (carregada globalmente no in√≠cio) representa best_model.joblib.
                 # Se 'model' foi carregado com sucesso, usamos o seu tipo.
                 # Isso informa o TIPO do best_model e a recomenda√ß√£o, independentemente de qual modelo est√° selecionado no momento.
                 if 'model' in globals() and model is not None:
                     best_model_type = type(model).__name__
                     st.info(f"O modelo recomendado √© o **{best_model_type}** ('best_model.joblib') pois foi o que obteve melhores resultados no conjunto de teste.")
                 # Removidos os warnings/erros redundantes aqui para simplificar a UI se best_model global n√£o carregar


            else: # Caso n√£o encontre nenhum ficheiro de modelo (model_files est√° vazio)
                 st.warning("Nenhum ficheiro de modelo (.joblib) encontrado na pasta 'artefacts/' para sele√ß√£o. Certifique-se de que os modelos foram salvos.")
                 selected_model_instance = None # Garante que selected_model_instance seja None
                 selected_model_filename = None # Garante que selected_model_filename seja None


        except FileNotFoundError:
             st.error("‚ùå A pasta 'artefacts/' n√£o foi encontrada. Certifique-se de que existe.")
             selected_model_instance = None
             selected_model_filename = None
        except Exception as e:
             st.error(f"‚ùå Ocorreu um erro ao listar ou carregar os modelos: {e}")
             selected_model_instance = None
             selected_model_filename = None


        st.markdown("### Dados do Aluno") # Subt√≠tulo antes dos inputs de dados

        st.markdown("#### Caracter√≠sticas Num√©ricas")
        # Abre o container do grid para as features num√©ricas
        st.markdown('<div class="input-grid-container">', unsafe_allow_html=True)

        # N√£o precisa de col_idx aqui, o grid cuida das colunas
        for feature in numeric_features:
            # Calcula os valores min/max/mean originais
            min_val_original = student_df_original[feature].min()
            max_val_original = student_df_original[feature].max()
            mean_val_original = student_df_original[feature].mean()

            # Determina o tipo de dado e formato apropriado para o input num√©rico
            if original_dtypes[feature] == 'int64' or feature in ordinal_numeric_features_to_map:
                # Para inteiros ou ordinais mapeadas (que s√£o int no dataset),
                # explicitamente converte min/max/mean para int, tratando NaN.
                input_min = int(min_val_original) if pd.notna(min_val_original) else 0
                input_max = int(max_val_original) if pd.notna(max_val_original) else None
                input_value = int(round(mean_val_original)) if pd.notna(mean_val_original) else (int(min_val_original) if pd.notna(min_val_original) else 0)
                input_step = 1
                input_format = "%d" # Formato para exibir como inteiro
            else: # Assume float ou outro tipo num√©rico
                # Para floats, use valores float e formato float
                input_min = float(min_val_original) if pd.notna(min_val_original) else 0.0
                input_max = float(max_val_original) if pd.notna(max_val_original) else None
                input_value = float(mean_val_original) if pd.notna(mean_val_original) else (float(min_val_original) if pd.notna(min_val_original) else 0.0)
                input_step = 0.1
                input_format = "%.2f" # Formato para exibir 2 casas decimais (ou remova para default do streamlit)

            # Abre o item do grid para esta feature
            st.markdown('<div class="grid-item">', unsafe_allow_html=True) # Corrigido para grid-item

            # --- Adiciona o nome da feature em negrito e a descri√ß√£o curta em letra menor ---
            # Usa o dicion√°rio feature_descriptions_short (que deve estar definido acima)
            description = feature_descriptions_short.get(feature, 'Descri√ß√£o n√£o dispon√≠vel')
            st.markdown(f"<div class='feature-label-container'><strong>{feature.replace('_', ' ').title()}</strong> <span class='small-description'>({description})</span></div>", unsafe_allow_html=True)

            # Verifica se a feature √© ordinal num√©rica para mostrar a descri√ß√£o da escala como info
            if feature in ordinal_numeric_features_to_map: # Assume ORDINAL_MAPPINGS is globally available
                mapping_dict = ORDINAL_MAPPINGS[feature]
                mapping_desc = ", ".join([f"{k}: {v}" for k, v in mapping_dict.items()])
                st.info(mapping_desc) # Mostra a descri√ß√£o como um info box

            # Cria o widget de input num√©rico
            # label="" para n√£o duplicar o nome j√° mostrado com Markdown
            input_data[feature] = st.number_input(
                 label="",
                min_value=input_min,
                max_value=input_max,
                value=input_value,
                step=input_step,
                format=input_format,
                key=f"input_{feature}" # Chave √∫nica
            )

            # Fecha o item do grid para esta feature
            st.markdown('</div>', unsafe_allow_html=True) # Corrigido para grid-item


        # Fecha o container do grid para as features num√©ricas
        st.markdown('</div>', unsafe_allow_html=True)


        st.markdown("#### Caracter√≠sticas Categ√≥ricas/Bin√°rias")
        # Abre um novo container do grid para as features categ√≥ricas
        st.markdown('<div class="input-grid-container">', unsafe_allow_html=True)
        # N√£o precisa de col_idx aqui dentro pois cada item do grid cuida da sua pr√≥pria coluna
        for feature in categorical_features:
             # Abre o item do grid para esta feature
             st.markdown('<div class="grid-item">', unsafe_allow_html=True) # Corrigido para grid-item

             # --- Adiciona o nome da feature em negrito e a descri√ß√£o curta em letra menor ---
             # Usa o dicion√°rio feature_descriptions_short (que deve estar definido acima)
             description = feature_descriptions_short.get(feature, 'Descri√ß√£o n√£o dispon√≠vel')
             st.markdown(f"<div class='feature-label-container'><strong>{feature.replace('_', ' ').title()}</strong> <span class='small-description'>({description})</span></div>", unsafe_allow_html=True)


             # Cria o widget de input selectbox com label vazio
             options = student_df_original[feature].dropna().unique().tolist()
             input_data[feature] = st.selectbox(
                 label="", # Label vazio para n√£o duplicar o nome j√° mostrado com Markdown
                 options=options,
                 index=options.index(student_df_original[feature].mode()[0]) if not student_df_original[feature].mode().empty and student_df_original[feature].mode()[0] in options else 0, # Usar o modo como default
                 key=f"input_{feature}" # Chave √∫nica
             )
             # Fecha o item do grid para esta feature
             st.markdown('</div>', unsafe_allow_html=True) # Corrigido para grid-item


        # Fecha o container do grid para as features categ√≥ricas
        st.markdown('</div>', unsafe_allow_html=True)


        st.markdown("---")
        # Verifica se o modelo foi carregado com sucesso antes de permitir a previs√£o
        if selected_model_instance is not None:
            if st.button("üöÄ Prever Resultado do Aluno"):
                # C√≥digo de previs√£o (mantido o mesmo, com ajustes nos warnings/erros conforme conversamos)
                # Criar DataFrame com dados de input, garantindo que todas as colunas originais estejam presentes
                input_df_raw = pd.DataFrame(columns=original_cols)
                input_df_raw.loc[0] = pd.NA # Inicializa com NA para garantir dtypes
                for col, val in input_data.items():
                     input_df_raw.loc[0, col] = val

                st.write("Dados de entrada para previs√£o:")
                st.dataframe(input_df_raw, use_container_width=True)


                loading_animation(f"Aplicando pr√©-processamento e prevendo com {selected_model_filename}...")
                try:
                    # Verificar se as colunas de input_df_raw correspondem √†s colunas que o preprocessor espera
                    if list(input_df_raw.columns) != list(original_cols):
                        st.error("‚ùå Erro de compatibilidade: As colunas dos dados de entrada n√£o correspondem √†s colunas originais esperadas pelo pr√©-processador.")
                        raise ValueError("Colunas de input incompat√≠veis")


                    input_processed = preprocessor.transform(input_df_raw) # Assume preprocessor is globally available
                    st.success("‚úÖ Pr√©-processamento aplicado.")

                    prediction = selected_model_instance.predict(input_processed) # Usa o modelo SELECIONADO

                    y_proba_input = None
                    if hasattr(selected_model_instance, 'predict_proba'):
                         try:
                              y_proba_input = selected_model_instance.predict_proba(input_processed) # Usa o modelo SELECIONADO
                         except Exception as proba_e:
                               st.info("Probabilidades n√£o dispon√≠veis para este modelo ou houve um erro ao calcul√°-las.")
                               y_proba_input = None


                    predicted_class_index = prediction[0]
                    # Garantir que o √≠ndice existe em CLASS_NAMES
                    if 0 <= predicted_class_index < len(CLASS_NAMES): # Assume CLASS_NAMES is globally available
                        predicted_class_label = CLASS_NAMES[predicted_class_index]
                    else:
                        predicted_class_label = f"√çndice Desconhecido ({predicted_class_index})"
                        st.error(f"Previs√£o retornou um √≠ndice de classe inesperado: {predicted_class_index}")


                    st.markdown('<h2 class="sub-header">Resultado da Previs√£o:</h2>', unsafe_allow_html=True)

                    if predicted_class_label == 'yes':
                         st.balloons()
                         st.success(f"üéâ Previs√£o: O aluno **PROVAVELMENTE PASSAR√Å** no exame final!")
                    elif predicted_class_label == 'no':
                         st.info(f"üòü Previs√£o: O aluno **PROVAVELMENTE N√ÉO PASSAR√Å** no exame final.")
                    else:
                         st.info(f"Previs√£o: {predicted_class_label}") # Mostrar label desconhecida em caso de erro


                    st.markdown("---")
                    st.markdown("#### Detalhes da Previs√£o")
                    st.write(f"- Modelo Utilizado: **{selected_model_filename}**") # Mostrar qual modelo foi usado
                    st.write(f"- Classe Prevista: **{predicted_class_label}**")

                    if y_proba_input is not None and y_proba_input.shape[1] == len(CLASS_NAMES): # Verifica se h√° probabilidades para todas as classes esperadas
                         try:
                              # Encontra a probabilidade da classe 'yes'
                              proba_yes = y_proba_input[0][CLASS_NAMES.index('yes')]
                              proba_no = y_proba_input[0][CLASS_NAMES.index('no')]

                              st.write(f"- Probabilidade de Passar ('yes'): **{proba_yes:.2f}**")
                              st.write(f"- Probabilidade de N√£o Passar ('no'): **{proba_no:.2f}**")
                         except ValueError:
                               st.info("N√£o foi poss√≠vel exibir as probabilidades para as classes esperadas.")
                         except Exception as e:
                               st.info(f"Ocorreu um erro ao exibir as probabilidades: {e}")

                    else:
                         st.info("Probabilidades n√£o dispon√≠veis ou incompat√≠veis para este modelo/previs√£o.")

                    st.info("Nota: Esta √© uma previs√£o baseada no modelo treinado e nos dados fornecidos.")

                except Exception as e:
                     st.error(f"‚ùå Ocorreu um erro ao fazer a previs√£o: {e}")
                     st.info("Verifique se todos os dados de entrada est√£o corretos e se o pr√©-processador e modelo carregados s√£o compat√≠veis.")
        else: # Mensagem se selected_model_instance for None (nenhum modelo carregado ou erro)
             st.warning("N√£o √© poss√≠vel fazer a previs√£o. Por favor, selecione um modelo v√°lido e verifique se os artefactos (modelos joblib) est√£o na pasta 'artefacts/'.")


# --- An√°lise do Modelo Treinado ---
elif menu == "An√°lise do Modelo Treinado":
    st.markdown('<h1 class="main-header">An√°lise do Modelo Treinado para Interven√ß√£o Estudantil</h1>', unsafe_allow_html=True)
    st.markdown('<p class="info-text">Aqui pode ver as m√©tricas de avalia√ß√£o, a matriz de confus√£o e a interpretabilidade do modelo (`best_model.joblib`) que foi treinado no seu dataset e guardado como artefacto.</p>', unsafe_allow_html=True)

    st.warning("‚ö†Ô∏è Esta sec√ß√£o mostra a performance do modelo PR√â-TREINADO (`best_model.joblib`) nos dados de teste processados. Para comparar diferentes algoritmos, v√° √† sec√ß√£o 'Avalia√ß√£o e Compara√ß√£o de Modelos'.")

    # Assume que test_df_processed_global, model, original_cols, processed_cols,
    # TARGET_PROCESSED_NAME, CLASS_NAMES est√£o definidos globalmente.

    if test_df_processed_global is None:
        st.warning("Conjunto de teste processado n√£o foi carregado. Esta sec√ß√£o n√£o est√° dispon√≠vel. Verifique o caminho do ficheiro 'data/processed/test_processed.csv'.")
    elif model is None: # 'model' √© a vari√°vel global carregada de best_model.joblib
         st.error("Modelo treinado ('best_model.joblib') n√£o foi carregado. Esta sec√ß√£o n√£o est√° dispon√≠vel. Verifique a pasta 'artefacts/'.")
    elif 'processed_cols' not in locals() or processed_cols is None:
         st.error("N√£o foi poss√≠vel carregar os nomes das caracter√≠sticas processadas. A sec√ß√£o de An√°lise do Modelo Treinado n√£o est√° dispon√≠vel.")
    else:
        # Verifica se a coluna alvo processada existe no dataframe de teste
        if TARGET_PROCESSED_NAME in test_df_processed_global.columns:
            # Prepara X_test e y_test usando os dados processados
            X_test_processed = test_df_processed_global.drop(columns=[TARGET_PROCESSED_NAME])
            y_test_processed = test_df_processed_global[TARGET_PROCESSED_NAME]

            # Verifica a compatibilidade das colunas de teste com as colunas processadas esperadas
            if list(X_test_processed.columns) != list(processed_cols):
                st.error("‚ùå Erro de compatibilidade: As colunas do conjunto de teste processado n√£o correspondem aos nomes das caracter√≠sticas processadas carregadas.")
                st.warning("Verifique se os ficheiros em 'data/processed/' e os artefactos foram gerados consistentemente.")
            else:
                # Bot√£o para iniciar a avalia√ß√£o
                if st.button("Avaliar o Modelo Treinado no Conjunto de Teste"):
                    loading_animation("Avaliando o modelo treinado...")
                    try:
                        # Faz previs√µes usando o modelo global 'model' (best_model.joblib)
                        y_pred_loaded_model = model.predict(X_test_processed)

                        # Tenta obter probabilidades se o modelo suportar
                        y_proba_loaded_model = None
                        if hasattr(model, 'predict_proba'):
                            try:
                                # Obt√©m probabilidades para as classes
                                # Assume que a classe positiva ('yes') corresponde √† coluna 1
                                y_proba_loaded_model = model.predict_proba(X_test_processed)
                            except Exception as proba_e:
                                st.info(f"Probabilidades n√£o dispon√≠veis para este modelo ou houve um erro ao calcul√°-las: {proba_e}")
                                y_proba_loaded_model = None


                        st.markdown('<h2 class="sub-header">M√©tricas de Avalia√ß√£o no Conjunto de Teste</h2>', unsafe_allow_html=True)

                        # --- Exibe M√©tricas de Avalia√ß√£o ---
                        accuracy = accuracy_score(y_test_processed, y_pred_loaded_model)
                        # Report de classifica√ß√£o
                        report_dict = classification_report(y_test_processed, y_pred_loaded_model,
                                                            target_names=CLASS_NAMES,
                                                            output_dict=True, zero_division=0)
                        report_df = pd.DataFrame(report_dict).transpose()

                        # AUC ROC (se probabilidades dispon√≠veis)
                        roc_auc = None
                        # Verifica se o modelo tem predict_proba e se tem 2 colunas de probabilidade
                        if y_proba_loaded_model is not None and y_proba_loaded_model.shape[1] == 2:
                             try:
                                  # Certifica-se que est√° a usar a probabilidade da classe 'yes' (classe 1)
                                  # Assume que a label 1 mapeia para 'yes' no y_test_processed
                                  roc_auc = roc_auc_score(y_test_processed, y_proba_loaded_model[:, 1])
                             except ValueError as auc_ve:
                                  st.warning(f"N√£o foi poss√≠vel calcular AUC ROC: {auc_ve}. Verifique as labels das classes nos dados de teste.")
                             except Exception as auc_e:
                                  st.warning(f"Erro inesperado ao calcular AUC ROC: {auc_e}")


                        col_metrics1, col_metrics2 = st.columns(2)

                        with col_metrics1:
                            st.markdown("#### Relat√≥rio de Classifica√ß√£o")
                            st.dataframe(report_df.round(2), use_container_width=True)

                            st.markdown("#### M√©tricas Resumo")
                            col_met1, col_met2, col_met3, col_met4 = st.columns(4)
                            with col_met1: st.metric("Acur√°cia", f"{accuracy:.2f}")
                            with col_met2:
                                 if 'weighted avg' in report_df.index:
                                     st.metric("Precis√£o (Avg)", f"{report_df.loc['weighted avg', 'precision']:.2f}")
                                 else: st.info("N/A")
                            with col_met3:
                                if 'weighted avg' in report_df.index:
                                    st.metric("Recall (Avg)", f"{report_df.loc['weighted avg', 'recall']:.2f}")
                                else: st.info("N/A")
                            with col_met4:
                                if 'weighted avg' in report_df.index:
                                    st.metric("F1-Score (Avg)", f"{report_df.loc['weighted avg', 'f1-score']:.2f}")
                                else: st.info("N/A")
                            # Exibe AUC ROC se calculado
                            if roc_auc is not None:
                                 st.metric("AUC ROC", f"{roc_auc:.2f}")
                            else:
                                 st.info("AUC ROC: N/A (Probabilidades n√£o dispon√≠veis ou erro)")


                        with col_metrics2:
                             # --- Exibe Matriz de Confus√£o ---
                             # Assumes plot_confusion_matrix_interactive is globally defined
                             fig_cm_loaded_model, cm_matrix_loaded_model = plot_confusion_matrix_interactive(y_test_processed, y_pred_loaded_model, class_names=CLASS_NAMES)
                             st.plotly_chart(fig_cm_loaded_model, use_container_width=True)

                        st.markdown("---")
                        st.markdown('<h3 class="sub-header">An√°lise da Matriz de Confus√£o</h3>', unsafe_allow_html=True)
                        # REMOVIDA a chamada para analyze_square_matrix aqui.
                        # analyze_square_matrix(cm_matrix_loaded_model, title="Propriedades Matem√°ticas da CM") # <-- REMOVIDO

                        # Exibe TP, TN, FP, FN para matriz 2x2 (mantido, √© relevante para CM)
                        if cm_matrix_loaded_model.shape == (2, 2):
                             # Assumindo classe 0 = 'no', classe 1 = 'yes' e que os resultados s√£o 0/1
                             # Verifica√ß√£o mais robusta pode usar model.classes_ se necess√°rio
                             if all(x in [0, 1] for x in np.unique(y_test_processed)) and all(x in [0, 1] for x in np.unique(y_pred_loaded_model)):
                                 tn, fp, fn, tp = cm_matrix_loaded_model[0,0], cm_matrix_loaded_model[0,1], cm_matrix_loaded_model[1,0], cm_matrix_loaded_model[1,1]
                                 st.write(f"**Verdadeiros Positivos (TP):** {tp}")
                                 st.write(f"**Verdadeiros Negativos (TN):** {tn}")
                                 st.write(f"**Falsos Positivos (FP):** {fp}")
                                 st.write(f"**Falsos Negativos (FN):** {fn}")
                                 st.info("""
                                 *   **TP:** Previsto Passou ('yes'), Real Passou ('yes')
                                 *   **TN:** Previsto N√£o Passou ('no'), Real N√£o Passou ('no')
                                 *   **FP:** Previsto Passou ('yes'), Real N√£o Passou ('no') - Interven√ß√£o perdida...
                                 *   **FN:** Previsto N√£o Passou ('no'), Real Passou ('yes') - Interven√ß√£o desnecess√°ria...
                                 """)
                                 st.warning("üí° No contexto de interven√ß√£o estudantil, Falsos Negativos (FN) s√£o geralmente mais cr√≠ticos, pois representam alunos que precisavam de ajuda mas n√£o foram identificados.")
                             else:
                                 st.warning("As labels das classes nos resultados n√£o s√£o 0 e 1. As m√©tricas TN/FP/FN/TP podem n√£o ser exibidas corretamente.")


                        # Mantido o separador e o t√≠tulo para a Import√¢ncia das Features
                        st.markdown('---')
                        st.markdown('<h3 class="sub-header">Import√¢ncia das Caracter√≠sticas (Modelo Treinado)</h3>', unsafe_allow_html=True)
                        st.markdown('<p class="info-text">Quais caracter√≠sticas foram mais relevantes para a decis√£o do seu modelo treinado (`best_model.joblib`), em rela√ß√£o aos dados P√ìS pr√©-processamento.</p>', unsafe_allow_html=True)

                        # Exibe Feature Importance ou Coeficientes para o modelo GLOBAL 'model' (best_model)
                        # Assume processed_cols is globally available
                        processed_feature_names_for_plot = processed_cols

                        if hasattr(model, 'feature_importances_'): # Usa o modelo global 'model'
                            # Ensure feature_importances_ length matches processed_feature_names_for_plot
                            if len(model.feature_importances_) == len(processed_feature_names_for_plot):
                                feature_importance_df = pd.DataFrame({
                                    'Caracter√≠stica Processada': processed_feature_names_for_plot,
                                    'Import√¢ncia': model.feature_importances_
                                }).sort_values('Import√¢ncia', ascending=False)

                                fig_importance = px.bar(
                                    feature_importance_df.head(min(30, len(feature_importance_df))), # Mostrar mais features se houver espa√ßo
                                    x='Import√¢ncia',
                                    y='Caracter√≠stica Processada',
                                    orientation='h',
                                    title=f"Import√¢ncia das Caracter√≠sticas (Processadas) para o Modelo Treinado ({type(model).__name__})" # Inclui o tipo do modelo
                                )
                                fig_importance.update_layout(yaxis={'categoryorder':'total ascending'})
                                st.plotly_chart(fig_importance, use_container_width=True)
                                st.info("A import√¢ncia mostrada √© para as caracter√≠sticas AP√ìS o pr√©-processamento (incluindo One-Hot Encoding, etc.).")
                            else:
                                st.error(f"‚ùå Erro: O n√∫mero de import√¢ncias ({len(model.feature_importances_)}) n√£o corresponde ao n√∫mero de caracter√≠sticas processadas ({len(processed_feature_names_for_plot)}).")
                                st.warning("Isso pode acontecer se os artefactos de colunas processadas n√£o corresponderem ao modelo guardado.")

                        elif hasattr(model, 'coef_'): # Usa o modelo global 'model'
                             # Verifica se o modelo √© linear e tem coeficientes por feature
                             if hasattr(model.coef_, 'ndim') and (model.coef_.ndim == 1 or (model.coef_.ndim == 2 and model.coef_.shape[0] == 1)) and len(model.coef_[0] if model.coef_.ndim == 2 else model.coef_) == len(processed_feature_names_for_plot):
                                  coef_values = model.coef_[0] if model.coef_.ndim == 2 else model.coef_ # Use coef_ for binary, first row for multi-class (simplistic)
                                  feature_coef_df = pd.DataFrame({
                                     'Caracter√≠stica Processada': processed_feature_names_for_plot,
                                     'Coeficiente': coef_values
                                  }).sort_values('Coeficiente', ascending=False)

                                  coef_min = feature_coef_df['Coeficiente'].min()
                                  coef_max = feature_coef_df['Coeficiente'].max()
                                  abs_max = max(abs(coef_min), abs(coef_max)) if coef_min is not None and coef_max is not None else 1.0 # Evitar divis√£o por zero

                                  fig_coef = px.bar(
                                      feature_coef_df.head(min(30, len(feature_coef_df))), # Mostrar mais features
                                      x='Coeficiente',
                                      y='Caracter√≠stica Processada',
                                      orientation='h',
                                      color='Coeficiente',
                                      color_continuous_scale='RdBu',
                                      range_color=[-abs_max, abs_max] if abs_max > 1e-9 else None, # Set range only if valid
                                      title=f"Coeficientes das Caracter√≠sticas (Processadas) para o Modelo Treinado ({type(model).__name__})" # Inclui o tipo do modelo
                                  )
                                  fig_coef.update_layout(yaxis={'categoryorder':'total ascending'})
                                  st.plotly_chart(fig_coef, use_container_width=True)
                                  st.info("Coeficientes mostrados s√£o para caracter√≠sticas AP√ìS pr√©-processamento. A magnitude indica a import√¢ncia; o sinal indica a dire√ß√£o do efeito na probabilidade da classe positiva.")
                             else:
                                st.warning("O modelo tem coeficientes, mas a visualiza√ß√£o direta √© complexa ou incompat√≠vel com as caracter√≠sticas processadas.")


                        else:
                            st.info(f"O modelo treinado ({type(model).__name__}) n√£o fornece import√¢ncia ou coeficientes de caracter√≠stica de forma padr√£o.")


                    except Exception as e:
                         st.error(f"‚ùå Ocorreu um erro ao avaliar o modelo treinado: {e}")
                         st.info("Verifique se o conjunto de teste processado corresponde ao formato esperado pelo modelo carregado.")

        else: # Handle case where target column is missing in processed test data
             st.warning(f"A coluna alvo processada '{TARGET_PROCESSED_NAME}' n√£o foi encontrada no conjunto de teste processado.")


# Importa√ß√µes adicionais necess√°rias (adicione no topo do seu script)
# from sklearn.tree import plot_tree
# import matplotlib.pyplot as plt # Para exibir a √°rvore de decis√£o

# Importa√ß√µes adicionais necess√°rias (adicione no topo do seu script, se ainda n√£o o fez)
# from sklearn.tree import plot_tree
# import matplotlib.pyplot as plt # Para exibir a √°rvore de decis√£o

# Importa√ß√µes adicionais necess√°rias (adicione no topo do seu script, se ainda n√£o o fez)
# from sklearn.tree import plot_tree
# import matplotlib.pyplot as plt # Para exibir a √°rvore de decis√£o

# --- An√°lise de Matriz (Modificado para apenas Matriz de Confus√£o por Modelo com An√°lises √önicas e sem propriedades matem√°ticas gen√©ricas da CM) ---
elif menu == "An√°lise de Matriz":
    # T√≠tulo e subt√≠tulo atualizados para refletir o foco na compara√ß√£o de modelos via CM
    st.markdown('<h1 class="main-header">Avalia√ß√£o e Compara√ß√£o de Modelos</h1>', unsafe_allow_html=True)
    st.markdown('<p class="info-text">Selecione diferentes tipos de modelos para visualizar a sua Matriz de Confus√£o, principais m√©tricas e algumas caracter√≠sticas √∫nicas do algoritmo no conjunto de teste processado.</p>', unsafe_allow_html=True)


    st.markdown('<h2 class="sub-header">Matriz de Confus√£o por Tipo de Modelo</h2>', unsafe_allow_html=True)
    st.markdown('<p class="info-text">Escolha um algoritmo de Machine Learning para treinar *temporariamente* nos seus dados de treino processados e avaliar o seu desempenho no conjunto de teste.</p>', unsafe_allow_html=True)


    # Verifica√ß√µes essenciais antes de tentar treinar e avaliar
    # Assume que train_df_processed_global, test_df_processed_global,
    # TARGET_PROCESSED_NAME, processed_cols, CLASS_NAMES,
    # AVAILABLE_MODELS_FOR_ANALYSIS est√£o definidos globalmente.
    if train_df_processed_global is None or test_df_processed_global is None:
        st.warning("Os conjuntos de treino ou teste processados n√£o foram carregados. N√£o √© poss√≠vel gerar a Matriz de Confus√£o ou m√©tricas. Verifique os ficheiros em 'data/processed/'.")
    elif 'processed_cols' not in locals() or processed_cols is None:
        st.error("N√£o foi poss√≠vel carregar os nomes das caracter√≠sticas processadas. A avalia√ß√£o de modelos n√£o est√° dispon√≠vel.")
    else:
        # Verifica se as colunas alvo processadas existem nos dataframes
        if TARGET_PROCESSED_NAME in train_df_processed_global.columns and TARGET_PROCESSED_NAME in test_df_processed_global.columns:
             # Prepara X e y para treino e teste
             X_train_processed = train_df_processed_global.drop(columns=[TARGET_PROCESSED_NAME])
             y_train_processed = train_df_processed_global[TARGET_PROCESSED_NAME]
             X_test_processed = test_df_processed_global.drop(columns=[TARGET_PROCESSED_NAME])
             y_test_processed = test_df_processed_global[TARGET_PROCESSED_NAME] # <-- Correta

             # Verifica a compatibilidade das colunas
             if list(X_train_processed.columns) != list(X_test_processed.columns) or list(X_train_processed.columns) != list(processed_cols): # Comparar com a lista carregada tamb√©m
                  st.error("‚ùå Erro de compatibilidade: As colunas dos dados de treino/teste processados n√£o correspondem aos nomes das features processadas carregadas.")
                  st.warning("Verifique se os ficheiros em 'data/processed/' foram gerados consistentemente com os artefactos.")
             else:
                # Selectbox para escolher o ALGORITMO (tipo de modelo)
                # Assumes AVAILABLE_MODELS_FOR_ANALYSIS is globally defined (no topo do script)
                selected_model_name = st.selectbox(
                    "Escolha o tipo de algoritmo para treinar e avaliar:",
                    list(AVAILABLE_MODELS_FOR_ANALYSIS.keys()),
                    key="cm_model_selector" # Chave √∫nica para este widget
                )

                # --- Op√ß√£o para configurar par√¢metros do modelo selecionado (Opcional) ---
                # Note: Estes par√¢metros aplicam-se apenas ao modelo TREINADO AQUI,
                # n√£o ao best_model.joblib da sec√ß√£o "An√°lise do Modelo Treinado".
                st.markdown('#### Configura√ß√£o do Algoritmo (Opcional)', unsafe_allow_html=True)
                current_model_key = selected_model_name # Usa o nome selecionado
                model_params = {} # Dicion√°rio para guardar par√¢metros configur√°veis

                # L√≥gica de configura√ß√£o baseada no tipo de modelo selecionado
                # Verifica se o modelo selecionado est√° no dicion√°rio AVAILABLE_MODELS_FOR_ANALYSIS
                if current_model_key in AVAILABLE_MODELS_FOR_ANALYSIS:
                    # Obt√©m a inst√¢ncia base do dicion√°rio para verificar o tipo e defaults
                    base_model_instance = AVAILABLE_MODELS_FOR_ANALYSIS[current_model_key]
                    # model_class = type(base_model_instance) # N√£o precisamos da classe aqui

                    # Adiciona sliders de par√¢metros comuns ou espec√≠ficos
                    if current_model_key == "KNN":
                        # Exemplo de par√¢metro para KNN: n_neighbors
                        # Usamos getattr para verificar se o atributo existe antes de tentar us√°-lo
                        default_n = getattr(base_model_instance, 'n_neighbors', 5) # Padr√£o 5 se n√£o existir ou for None
                        model_params['n_neighbors'] = st.slider(f"{current_model_key}: N√∫mero de Vizinhos (n_neighbors)", 1, min(20, len(X_train_processed)), int(default_n), key=f"{current_model_key}_n_neighbors") # Max vizinhos limitado pelo tamanho do treino


                    elif current_model_key in ["Decision Tree", "Random Forest"]:
                        # Par√¢metros comuns para √°rvores
                        # Valor m√°ximo razo√°vel para max_depth, None significa profundidade total
                        # max_possible_depth = base_model_instance.get_params().get('max_depth', 1000) # Get default if any (not needed here)
                        default_max_depth = getattr(base_model_instance, 'max_depth', 3 if current_model_key == "Decision Tree" else 5) # Padr√£o diferente para DT vs RF
                        # Slider para max_depth - Adicionar op√ß√£o 'Profundidade Total' ou None? Sliders n√£o suportam None.
                        # Vamos usar um valor alto para "quase total" ou limitar a um valor razo√°vel.
                        slider_max_depth = st.slider(f"{current_model_key}: Profundidade M√°xima (max_depth)", 1, 15, int(default_max_depth) if default_max_depth is not None and default_max_depth <= 15 else (3 if current_model_key == "Decision Tree" else 5), key=f"{current_model_key}_max_depth")
                        model_params['max_depth'] = slider_max_depth # Atribui o valor do slider

                        default_min_samples_split = getattr(base_model_instance, 'min_samples_split', 2)
                        model_params['min_samples_split'] = st.slider(f"{current_model_key}: M√≠nimo de Amostras para Dividir (min_samples_split)", 2, 20, int(default_min_samples_split), key=f"{current_model_key}_min_samples_split")

                        if current_model_key == "Random Forest":
                            default_n_estimators = getattr(base_model_instance, 'n_estimators', 100)
                            model_params['n_estimators'] = st.slider(f"{current_model_key}: N√∫mero de √Årvores (n_estimators)", 50, 500, int(default_n_estimators), key=f"{current_model_key}_n_estimators")

                    elif current_model_key in ["Regress√£o Log√≠stica", "SVM (Kernel RBF)", "Gradient Boosting", "AdaBoost"]:
                         # Adicionar par√¢metros para estes modelos se quiser
                         pass # Por agora, sem par√¢metros configur√°veis para estes


                else: # No specific configurable parameters for this model in the list above
                    st.info(f"N√£o h√° par√¢metros configur√°veis dispon√≠veis para o algoritmo **{current_model_key}** neste momento.")


                if st.button(f"Treinar e Avaliar {selected_model_name}", key="train_evaluate_button"): # Adicionada chave para evitar Warning
                    loading_animation(f"Treinando {selected_model_name} com {len(X_train_processed)} amostras e avaliando em {len(X_test_processed)} amostras...")
                    try:
                        # Obt√©m a inst√¢ncia base do modelo e cria uma nova inst√¢ncia com os par√¢metros configurados
                        if current_model_key in AVAILABLE_MODELS_FOR_ANALYSIS:
                            base_model_instance = AVAILABLE_MODELS_FOR_ANALYSIS[current_model_key]
                            model_class = type(base_model_instance)
                            # Cria uma nova inst√¢ncia com os par√¢metros configurados
                            model_instance = model_class(**model_params)

                            # Treina o modelo nos dados de treino processados
                            model_instance.fit(X_train_processed, y_train_processed)

                            # Faz previs√µes no conjunto de teste processado
                            y_pred = model_instance.predict(X_test_processed)

                            # Tenta obter probabilidades se o modelo suportar
                            y_proba_loaded_model = None
                            if hasattr(model_instance, 'predict_proba'):
                                try:
                                    y_proba_loaded_model = model_instance.predict_proba(X_test_processed)
                                except Exception as proba_e:
                                    st.info(f"Probabilidades (predict_proba) n√£o dispon√≠veis para {selected_model_name} ou houve um erro ao calcul√°-las: {proba_e}")
                                    y_proba_loaded_model = None

                            st.markdown('<h3 class="sub-header">Resultados de Avalia√ß√£o no Conjunto de Teste</h3>', unsafe_allow_html=True)

                            # --- Exibe M√©tricas de Avalia√ß√£o ---
                            accuracy = accuracy_score(y_test_processed, y_pred)
                            report_dict = classification_report(y_test_processed, y_pred,
                                                                target_names=CLASS_NAMES,
                                                                output_dict=True, zero_division=0)
                            report_df = pd.DataFrame(report_dict).transpose()

                            # AUC ROC (se probabilidades dispon√≠veis e bin√°rio)
                            roc_auc = None
                            # Verifica se o modelo tem predict_proba e se √© um problema de classifica√ß√£o bin√°ria (2 classes)
                            if y_proba_loaded_model is not None and y_proba_loaded_model.shape[1] == 2 and len(model_instance.classes_) == 2:
                                try:
                                    # Encontra o √≠ndice da classe positiva ('yes') nas classes do modelo treinado
                                    class_labels_in_model = list(model_instance.classes_)
                                    # Preferir label num√©rica 1 se existir e 'yes' for a classe positiva
                                    positive_class_label_in_model = None
                                    if 'yes' in class_labels_in_model:
                                        positive_class_label_in_model = 'yes'
                                    elif 1 in class_labels_in_model: # Se 1 existir
                                        positive_class_label_in_model = 1
                                    elif len(class_labels_in_model) == 2: # Bin√°rio com outras labels, assumir a segunda como positiva
                                         positive_class_label_in_model = class_labels_in_model[1]

                                    if positive_class_label_in_model is not None:
                                        positive_class_index_in_model = class_labels_in_model.index(positive_class_label_in_model)
                                        # Certifica-se que y_test_processed tem as labels corretas (0 e 1 ou 'no' e 'yes') para roc_auc_score
                                        # roc_auc_score espera y_true com 0s e 1s
                                        y_true_binary_for_auc = y_test_processed.map({'no': 0, 'yes': 1}) if y_test_processed.dtype == 'object' else y_test_processed
                                        # Se o target original era num√©rico, pode j√° ser 0/1. Se era categ√≥rico ('no'/'yes'), precisa do map.

                                        # Verifica se y_true_binary_for_auc tem apenas 0s e 1s (ap√≥s o map, se aplic√°vel)
                                        if all(x in [0, 1] for x in y_true_binary_for_auc.dropna().unique()):
                                             roc_auc = roc_auc_score(y_true_binary_for_auc, y_proba_loaded_model[:, positive_class_index_in_model])
                                        else:
                                             st.warning("Formato inesperado na coluna alvo de teste para c√°lculo de AUC ROC. Esperava 0s e 1s ap√≥s mapeamento.")


                                    else:
                                         st.warning(f"Classe positiva ('yes' ou 1) n√£o encontrada nas classes do modelo treinado: {class_labels_in_model}. N√£o √© poss√≠vel calcular AUC ROC.")

                                except ValueError as auc_ve:
                                     st.warning(f"N√£o foi poss√≠vel calcular AUC ROC: {auc_ve}. Verifique as labels das classes.")
                                except Exception as auc_e:
                                     st.warning(f"Erro inesperado ao calcular AUC ROC: {auc_e}")


                            col_metrics1, col_metrics2 = st.columns(2)

                            with col_metrics1:
                                st.markdown(f"#### Relat√≥rio de Classifica√ß√£o ({selected_model_name})")
                                st.dataframe(report_df.round(2), use_container_width=True)

                                st.markdown("#### M√©tricas Resumo")
                                col_met1, col_met2, col_met3, col_met4 = st.columns(4)
                                with col_met1: st.metric("Acur√°cia", f"{accuracy:.2f}")
                                with col_met2:
                                     if 'weighted avg' in report_df.index:
                                         st.metric("Precis√£o (Avg)", f"{report_df.loc['weighted avg', 'precision']:.2f}")
                                     else: st.info("N/A")
                                with col_met3:
                                    if 'weighted avg' in report_df.index:
                                        st.metric("Recall (Avg)", f"{report_df.loc['weighted avg', 'recall']:.2f}")
                                    else: st.info("N/A")
                                with col_met4:
                                    if 'weighted avg' in report_df.index:
                                        st.metric("F1-Score (Avg)", f"{report_df.loc['weighted avg', 'f1-score']:.2f}")
                                    else: st.info("N/A")
                                # Exibe AUC ROC se calculado
                                if roc_auc is not None:
                                     st.metric("AUC ROC", f"{roc_auc:.2f}")
                                else:
                                     st.info("AUC ROC: N/A (Probabilidades n√£o dispon√≠veis ou erro)")


                            with col_metrics2:
                                 # --- Exibe Matriz de Confus√£o ---
                                 fig_cm, cm_matrix = plot_confusion_matrix_interactive(y_test_processed, y_pred, class_names=CLASS_NAMES)
                                 st.plotly_chart(fig_cm, use_container_width=True)

                            st.markdown("---")
                            st.markdown('<h3 class="sub-header">An√°lise da Matriz de Confus√£o</h3>', unsafe_allow_html=True)
                            # REMOVIDA a chamada para analyze_square_matrix aqui.
                            # analyze_square_matrix(cm_matrix, title="Propriedades Matem√°ticas da CM") # <-- REMOVIDO

                            # Exibe TP, TN, FP, FN para matriz 2x2
                            if cm_matrix.shape == (2, 2):
                                 # Assumindo classe 0 = 'no', classe 1 = 'yes' e que os resultados s√£o 0/1
                                 # Verifica√ß√£o mais robusta pode usar model_instance.classes_ se necess√°rio
                                 # A l√≥gica aqui deve espelhar o que √© feito no AUC ROC para as labels
                                 class_labels_in_model = list(model_instance.classes_)
                                 try: # Usar try-except para acesso seguro aos elementos da CM
                                     # Encontra os √≠ndices para 'no' (0) e 'yes' (1) nas classes do modelo
                                     no_idx_in_model = class_labels_in_model.index('no') if 'no' in class_labels_in_model else (class_labels_in_model.index(0) if 0 in class_labels_in_model else None)
                                     yes_idx_in_model = class_labels_in_model.index('yes') if 'yes' in class_labels_in_model else (class_labels_in_model.index(1) if 1 in class_labels_in_model else None)

                                     if no_idx_in_model is not None and yes_idx_in_model is not None:
                                         # Assumindo que a Matriz de Confus√£o gerada pelo sklearn segue a ordem model_instance.classes_
                                         # cm[real_idx, predicted_idx]
                                         tn = cm_matrix[no_idx_in_model, no_idx_in_model]
                                         fp = cm_matrix[no_idx_in_model, yes_idx_in_model]
                                         fn = cm_matrix[yes_idx_in_model, no_idx_in_model]
                                         tp = cm_matrix[yes_idx_in_model, yes_idx_in_model]

                                         st.write(f"**Verdadeiros Positivos (TP):** {tp}")
                                         st.write(f"**Verdadeiros Negativos (TN):** {tn}")
                                         st.write(f"**Falsos Positivos (FP):** {fp}")
                                         st.write(f"**Falsos Negativos (FN):** {fn}")
                                         st.info("TP: Previsto Passou, Real Passou | TN: Previsto N√£o Passou, Real N√£o Passou | FP: Previsto Passou, Real N√£o Passou | FN: Previsto N√£o Passou, Real Passou")
                                         st.warning("üí° No contexto de interven√ß√£o estudantil, Falsos Negativos (FN) s√£o geralmente mais cr√≠ticos, pois representam alunos que precisavam de ajuda mas n√£o foram identificados.")
                                     else:
                                        st.warning("N√£o foi poss√≠vel determinar os √≠ndices das classes 'no' e 'yes' nas classes do modelo para extrair TP/TN/FP/FN da Matriz de Confus√£o.")

                                 except IndexError:
                                      st.warning("Erro ao acessar elementos da Matriz de Confus√£o. As dimens√µes ou √≠ndices das classes podem estar incorretos.")
                                 except Exception as cm_extract_e:
                                      st.warning(f"Erro inesperado ao extrair TP/TN/FP/FN: {cm_extract_e}")


                            st.markdown("---")
                            st.markdown(f'<h3 class="sub-header">An√°lise √önica do Algoritmo: {selected_model_name}</h3>', unsafe_allow_html=True)

                            # --- Adiciona visualiza√ß√µes/informa√ß√µes √∫nicas por TIPO DE MODELO ---
                            # Assume processed_cols is globally available for feature names
                            feature_names_processed = X_train_processed.columns.tolist()


                            if selected_model_name == "Decision Tree":
                                st.write("#### Visualiza√ß√£o da √Årvore")
                                # Verifica se a √°rvore tem profundidade maior que 0 antes de tentar plotar
                                # get_depth() retorna None para √°rvores n√£o treinadas ou com apenas um n√≥
                                if model_instance.get_depth() is not None and model_instance.get_depth() > 0:
                                    st.info(f"A visualiza√ß√£o exibe a √°rvore at√© a profundidade **{model_params.get('max_depth', 'total')}** configurada ou at√© 6 n√≠veis para clareza visual. Considere ajustar a profundidade m√°xima (max_depth) nas configura√ß√µes acima.")
                                    # Determina a profundidade a plotar: a menor entre a profundidade real, a profundidade configurada pelo slider e um limite visual
                                    max_depth_from_params = model_params.get('max_depth')
                                    tree_actual_depth = model_instance.get_depth()
                                    max_visual_limit = 6 # Limite visual fixo recomendado para plot_tree

                                    # Calculate depth_to_plot ensuring we don't pass None to min
                                    depth_options = [tree_actual_depth if tree_actual_depth is not None else float('inf'),
                                                     max_depth_from_params if max_depth_from_params is not None else float('inf'),
                                                     max_visual_limit]
                                    depth_to_plot = int(min(depth_options))


                                    # Ajusta o tamanho da figura baseado na profundidade a plotar
                                    fig_width = max(20, len(feature_names_processed) * 1.5) # Ajusta largura com base no n√∫mero de features? Pode ser muito largo.
                                    fig_width = min(fig_width, 40) # Limite m√°ximo de largura para n√£o ficar excessivo
                                    fig_height = max(8, depth_to_plot * 2.5) # Ajusta altura com base na profundidade


                                    fig_tree, ax_tree = plt.subplots(figsize=(fig_width, fig_height))

                                    try:
                                        plot_tree(model_instance, # Usar a inst√¢ncia treinada
                                                ax=ax_tree, # <-- Passar o Axes
                                                filled=True,
                                                feature_names=feature_names_processed,
                                                class_names=[str(c) for c in CLASS_NAMES],
                                                rounded=True,
                                                fontsize=8,
                                                max_depth=depth_to_plot, # Usar a profundidade calculada para plotar
                                                impurity=False, # Ocultar impureza para clareza
                                                node_ids=False, # Ocultar IDs dos n√≥s
                                                proportion=True, # Mostrar propor√ß√£o de amostras
                                                # rotate=True # Opcional: rotacionar para mais espa√ßo horizontal
                                                )
                                        st.pyplot(fig_tree)
                                    except Exception as tree_e:
                                        st.error(f"‚ùå N√£o foi poss√≠vel gerar a visualiza√ß√£o da √°rvore: {tree_e}. A √°rvore pode ser muito complexa ou h√° um problema com as depend√™ncias (verifique matplotlib e Graphviz).")
                                    finally:
                                        plt.close(fig_tree)
                                else:
                                     st.info("A √°rvore de decis√£o treinada tem profundidade 0 (apenas um n√≥, ou seja, s√≥ faz uma previs√£o baseada na classe majorit√°ria). N√£o h√° estrutura de √°rvore para visualizar.")


                            elif selected_model_name == "Random Forest":
                                st.write("#### Visualiza√ß√£o de uma √Årvore no Random Forest")
                                st.info(f"Random Forest √© um ensemble de **{model_instance.n_estimators}** √°rvores. Aqui est√° a visualiza√ß√£o da **primeira √°rvore** (`estimators_[0]`). Considere reduzir a profundidade m√°xima (max_depth) nas configura√ß√µes acima para uma visualiza√ß√£o mais clara.")
                                # Visualiza a primeira √°rvore na floresta
                                if hasattr(model_instance, 'estimators_') and len(model_instance.estimators_) > 0:
                                    estimator = model_instance.estimators_[0] # Primeira √°rvore

                                    # Determina a profundidade a plotar: similar √† Decision Tree
                                    max_depth_from_params = model_params.get('max_depth')
                                    estimator_actual_depth = estimator.get_depth() if hasattr(estimator, 'get_depth') and estimator.get_depth() is not None else 1000
                                    max_visual_limit = 6

                                    depth_options_rf = [estimator_actual_depth,
                                                        max_depth_from_params if max_depth_from_params is not None else float('inf'),
                                                        max_visual_limit]
                                    depth_to_plot_rf = int(min(depth_options_rf))


                                    if depth_to_plot_rf > 0: # S√≥ plotar se a √°rvore n√£o for trivial
                                         # Ajusta o tamanho da figura baseado na profundidade a plotar
                                         fig_width_rf = max(20, len(feature_names_processed) * 1.5)
                                         fig_width_rf = min(fig_width_rf, 40) # Limite m√°ximo
                                         fig_height_rf = max(8, depth_to_plot_rf * 2.5)

                                         fig_tree_rf, ax_tree_rf = plt.subplots(figsize=(fig_width_rf, fig_height_rf))
                                         try:
                                             plot_tree(estimator,
                                                     ax=ax_tree_rf, # <-- Passar o Axes
                                                     filled=True,
                                                     feature_names=feature_names_processed, # Usar nomes das features processadas
                                                     class_names=[str(c) for c in CLASS_NAMES],
                                                     rounded=True,
                                                     fontsize=8,
                                                     max_depth=depth_to_plot_rf,
                                                     impurity=False,
                                                     node_ids=False,
                                                     proportion=True
                                                     )
                                             st.pyplot(fig_tree_rf)
                                         except Exception as tree_e:
                                             st.error(f"‚ùå N√£o foi poss√≠vel gerar a visualiza√ß√£o da √°rvore: {tree_e}. A √°rvore pode ser muito complexa ou h√° um problema com as depend√™ncias.")
                                         finally:
                                              plt.close(fig_tree_rf)
                                    else:
                                        st.info("A primeira √°rvore do Random Forest tem profundidade 0 (apenas um n√≥). N√£o h√° estrutura de √°rvore para visualizar.")


                                    # Opcional: Mostrar Import√¢ncia das Features do Random Forest como um todo
                                    if hasattr(model_instance, 'feature_importances_'):
                                        st.write("#### Import√¢ncia das Caracter√≠sticas (Random Forest)")
                                        try:
                                            feature_importance_df_rf = pd.DataFrame({
                                                'Caracter√≠stica Processada': feature_names_processed, # Usar nomes das features processadas
                                                'Import√¢ncia': model_instance.feature_importances_
                                            }).sort_values('Import√¢ncia', ascending=False)

                                            fig_importance_rf = px.bar(
                                                feature_importance_df_rf.head(min(20, len(feature_importance_df_rf))), # Mostrar top 20 ou menos
                                                x='Import√¢ncia',
                                                y='Caracter√≠stica Processada',
                                                orientation='h',
                                                color_continuous_scale=px.colors.sequential.Viridis, # Cores diferentes para distin√ß√£o
                                                title="Import√¢ncia Global das Caracter√≠sticas (Random Forest)"
                                            )
                                            fig_importance_rf.update_layout(yaxis={'categoryorder':'total ascending'})
                                            st.plotly_chart(fig_importance_rf, use_container_width=True)
                                            st.info("A import√¢ncia das caracter√≠sticas em modelos de ensemble baseados em √°rvores √© a soma das import√¢ncias que cada caracter√≠stica contribui para a redu√ß√£o da impureza ou erro em todas as √°rvores do ensemble.")
                                        except Exception as imp_e:
                                             st.error(f"‚ùå N√£o foi poss√≠vel exibir a import√¢ncia das features do Random Forest: {imp_e}")
                                else:
                                     st.info(f"O modelo Random Forest ({selected_model_name}) n√£o tem estimadores treinados acess√≠veis.")


                            elif selected_model_name in ["Regress√£o Log√≠stica", "SVM (Kernel Linear)"]: # Assume SVM com kernel linear se o tipo for 'SVC' e voc√™ o configura com kernel='linear' em AVAILABLE_MODELS_FOR_ANALYSIS
                                st.write("#### Coeficientes das Caracter√≠sticas")
                                # Para modelos lineares, coef_ mostra a influ√™ncia de cada feature
                                if hasattr(model_instance, 'coef_'):
                                    try:
                                         # Assume coef_ √© 1D para classifica√ß√£o bin√°ria, ou 2D (n_classes, n_features)
                                         coef_values = model_instance.coef_[0] if model_instance.coef_.ndim == 2 else model_instance.coef_
                                         # Usar feature_names_processed (colunas de X_train_processed)
                                         feature_coef_df = pd.DataFrame({
                                            'Caracter√≠stica Processada': feature_names_processed,
                                            'Coeficiente': coef_values
                                         }).sort_values('Coeficiente', ascending=False)

                                         coef_min = feature_coef_df['Coeficiente'].min()
                                         coef_max = feature_coef_df['Coeficiente'].max()
                                         # Adiciona um pequeno epsilon para evitar divis√£o por zero se todos os coeficientes forem 0
                                         abs_max = max(abs(coef_min), abs(coef_max)) if (coef_min is not None and coef_max is not None and (abs(coef_min) > 1e-9 or abs(coef_max) > 1e-9)) else 1.0

                                         fig_coef = px.bar(
                                             feature_coef_df.head(min(30, len(feature_coef_df))),
                                             x='Coeficiente',
                                             y='Caracter√≠stica Processada',
                                             orientation='h',
                                             color='Coeficiente',
                                             color_continuous_scale='RdBu',
                                             range_color=[-abs_max, abs_max] if abs_max > 1e-9 else [-1, 1],
                                             title=f"Coeficientes para {selected_model_name}"
                                         )
                                         fig_coef.update_layout(yaxis={'categoryorder':'total ascending'})
                                         st.plotly_chart(fig_coef, use_container_width=True)
                                         st.info("A magnitude do coeficiente indica a import√¢ncia da caracter√≠stica; o sinal indica a dire√ß√£o da rela√ß√£o com a classe positiva (geralmente 1).")
                                    except Exception as coef_e:
                                         st.error(f"‚ùå N√£o foi poss√≠vel visualizar os coeficientes: {coef_e}. Verifique a estrutura do objeto coef_ do modelo.")
                                else:
                                    st.info(f"Este modelo ({selected_model_name}) n√£o tem coeficientes acess√≠veis ou n√£o √© linear.")


                            elif selected_model_name == "KNN":
                                st.write("#### Princ√≠pios do KNN")
                                st.info(f"""
                                O algoritmo K-Nearest Neighbors ({selected_model_name}) faz previs√µes baseando-se nos **{model_instance.n_neighbors}** vizinhos mais pr√≥ximos da amostra no espa√ßo de caracter√≠sticas.
                                *   **Como funciona:** Para classificar uma nova amostra, o KNN encontra as **{model_instance.n_neighbors}** amostras mais pr√≥ximas nos dados de treino e atribui √† nova amostra a classe mais comum entre esses vizinhos.
                                *   **Par√¢metro chave:** `n_neighbors` (N√∫mero de Vizinhos), configurado aqui como {model_instance.n_neighbors}.
                                """)


                            elif selected_model_name in ["Gradient Boosting", "AdaBoost"]:
                                st.write(f"#### Princ√≠pios de Modelos de Boosting ({selected_model_name})")
                                st.info(f"""
                                Modelos de Boosting como {selected_model_name} constroem um ensemble de modelos fracos (geralmente √°rvores de decis√£o pequenas), aprendendo sequencialmente onde os modelos anteriores erraram.
                                *   **Gradient Boosting:** Constr√≥i √°rvores sequencialmente, onde cada nova √°rvore tenta corrigir os erros residuais do ensemble anterior. O par√¢metro chave `n_estimators` (n√∫mero de √°rvores) e `learning_rate` (taxa de aprendizado) controlam o processo.
                                *   **AdaBoost:** Tamb√©m constr√≥i modelos sequencialmente, mas ajusta o peso das amostras, dando mais import√¢ncia √†s que foram mal classificadas pelos modelos anteriores. O par√¢metro chave `n_estimators` (n√∫mero de estimadores base) e `learning_rate` controlam o processo.
                                Estes modelos s√£o poderosos mas podem ser mais dif√≠ceis de interpretar diretamente do que uma √∫nica √°rvore ou modelo linear.
                                """)
                                # Opcional: Mostrar Import√¢ncia das Features para Boosting
                                if hasattr(model_instance, 'feature_importances_'):
                                    st.write(f"#### Import√¢ncia das Caracter√≠sticas ({selected_model_name})")
                                    try:
                                        feature_importance_df_boost = pd.DataFrame({
                                            'Caracter√≠stica Processada': feature_names_processed, # Usar nomes das features processadas
                                            'Import√¢ncia': model_instance.feature_importances_
                                        }).sort_values('Import√¢ncia', ascending=False)

                                        fig_importance_boost = px.bar(
                                            feature_importance_df_boost.head(min(20, len(feature_importance_df_boost))), # Mostrar top 20 ou menos
                                            x='Import√¢ncia',
                                            y='Caracter√≠stica Processada',
                                            orientation='h',
                                            color_continuous_scale=px.colors.sequential.Viridis, # Cores diferentes para distin√ß√£o
                                            title=f"Import√¢ncia Global das Caracter√≠sticas ({selected_model_name})"
                                        )
                                        fig_importance_boost.update_layout(yaxis={'categoryorder':'total ascending'})
                                        st.plotly_chart(fig_importance_boost, use_container_width=True)
                                        st.info("A import√¢ncia das caracter√≠sticas em modelos de ensemble baseados em √°rvores √© a soma das import√¢ncias que cada caracter√≠stica contribui para a redu√ß√£o da impureza ou erro em todas as √°rvores do ensemble.")
                                    except Exception as imp_e:
                                         st.error(f"‚ùå N√£o foi poss√≠vel exibir a import√¢ncia das features do {selected_model_name}: {imp_e}")
                                else:
                                     st.info(f"O modelo {selected_model_name} n√£o suporta import√¢ncia de features.")


                            elif selected_model_name == "SVM (Kernel RBF)": # RBF kernel n√£o √© linear, coef_ n√£o se aplica diretamente
                                st.write("#### Princ√≠pios do SVM com Kernel RBF")
                                st.info("""
                                O Support Vector Machine (SVM) com Kernel RBF √© um modelo n√£o-linear que encontra um hiperplano de separa√ß√£o no espa√ßo de caracter√≠sticas.
                                *   **Kernel RBF:** Permite mapear os dados para um espa√ßo de dimens√£o mais alta onde a separa√ß√£o pode ser mais f√°cil, mesmo que n√£o seja linear no espa√ßo original. √â eficaz para rela√ß√µes complexas.
                                *   **Par√¢metros chaves:** `C` (penalidade do erro) e `gamma` (influ√™ncia de um √∫nico exemplo de treino).
                                A interpretabilidade direta das "import√¢ncias" das caracter√≠sticas n√£o √© t√£o simples quanto em modelos lineares ou baseados em √°rvores.
                                """)


                            else:
                                st.info(f"N√£o h√° an√°lise √∫nica espec√≠fica configurada para o algoritmo **{selected_model_name}** neste momento. Veja as m√©tricas e a Matriz de Confus√£o acima para avaliar o seu desempenho.")

                        else: # Caso current_model_key n√£o esteja em AVAILABLE_MODELS_FOR_ANALYSIS (n√£o deveria acontecer)
                             st.error(f"Erro interno: Tipo de modelo '{current_model_key}' n√£o reconhecido em AVAILABLE_MODELS_FOR_ANALYSIS.")


                    except Exception as e:
                         st.error(f"‚ùå Ocorreu um erro ao treinar ou avaliar o modelo {selected_model_name}: {e}")
                         st.warning("Verifique a compatibilidade entre o modelo e os dados processados, ou se h√° problemas com a inst√¢ncia do modelo selecionado. Erro detalhado: " + str(e))


        else: # Handle cases where target is missing in processed dataframes
             if TARGET_PROCESSED_NAME not in train_df_processed_global.columns:
                  st.error(f"A coluna alvo '{TARGET_PROCESSED_NAME}' n√£o foi encontrada no dataframe de treino processado.")
             if TARGET_PROCESSED_NAME not in test_df_processed_global.columns:
                  st.error(f"A coluna alvo '{TARGET_PROCESSED_NAME}' n√£o foi encontrada no dataframe de teste processado.")


    # REMOVIDOS os blocos elif para Matriz de Correla√ß√£o, Matriz de Covari√¢ncia e Matriz Personalizada
    # Eles n√£o s√£o necess√°rios para comparar modelos.

# --- Documenta√ß√£o ---
elif menu == "Documenta√ß√£o":
    st.markdown('<h1 class="main-header">Documenta√ß√£o e Exemplos</h1>', unsafe_allow_html=True)
    st.markdown('<p class="info-text">Bem-vindo √† sec√ß√£o de documenta√ß√£o...</p>', unsafe_allow_html=True)

    st.markdown('<h2 class="sub-header">Sobre o Dataset</h2>', unsafe_allow_html=True)
    st.markdown(f"""
    A aplica√ß√£o utiliza o seu dataset original: **`student-data.csv`**. Este dataset cont√©m informa√ß√µes sobre alunos...
    """)
    st.markdown('### Descri√ß√£o das Caracter√≠sticas (Features)', unsafe_allow_html=True)
    st.markdown('<p class="info-text">Aqui est√° a lista completa das caracter√≠sticas do dataset e o seu significado:</p>', unsafe_allow_html=True)

    # Exibir a lista de features com suas descri√ß√µes (usa o dicion√°rio completo)
    for feature, desc in full_feature_descriptions.items():
        # Adiciona formata√ß√£o condicional para a vari√°vel alvo
        if feature == TARGET_ORIGINAL_NAME:
             st.markdown(f"- **{feature.replace('_', ' ').title()}**: {desc} **(Vari√°vel Alvo)**")
        else:
             st.markdown(f"- **{feature.replace('_', ' ').title()}**: {desc}")


    st.markdown('<h2 class="sub-header">Sobre o Modelo de Previs√£o</h2>', unsafe_allow_html=True)
    st.markdown("""
    Um modelo de classifica√ß√£o bin√°ria foi treinado no dataset `student-data.csv` para prever se um aluno passar√° ou n√£o...
    *   O **Pr√©-processador** (`preprocessor.joblib`) √© respons√°vel por transformar os dados brutos do aluno para o formato que o modelo entende.
    *   O **Modelo Treinado Principal** (`best_model.joblib`) √© o resultado do processo de treino e otimiza√ß√£o realizado no seu notebook e √© usado para a Previs√£o Individual e sec√ß√£o de An√°lise.
    Pode obter previs√µes individuais na sec√ß√£o "Previs√£o Individual" e ver a avalia√ß√£o detalhada deste modelo principal no conjunto de teste na sec√ß√£o "An√°lise do Modelo Treinado".
    """)

    st.markdown('<h2 class="sub-header">Sobre a An√°lise de Matriz</h2>', unsafe_allow_html=True)
    st.markdown("""
    A sec√ß√£o "An√°lise de Matriz" permite visualizar e analisar propriedades matem√°ticas...
    *   **Matriz de Confus√£o (Escolher Modelo):** Permite selecionar diferentes tipos de modelos para visualizar o seu desempenho *tempor√°rio* no conjunto de teste processado. √ötil para comparar o desempenho de diferentes algoritmos.
    *   **Matriz de Correla√ß√£o (Seu Dataset):** Mostra a correla√ß√£o linear entre pares de vari√°veis num√©ricas no seu dataset original.
    *   **Matriz de Covari√¢ncia (Seu Dataset):** Semelhante √† correla√ß√£o, mas dependente da escala...
    *   **Matriz Personalizada:** Permite introduzir qualquer matriz quadrada...
    """)

    st.markdown('<h2 class="sub-header">Pr√≥ximos Passos e Melhorias</h2>', unsafe_allow_html=True)
    st.markdown("""
    Pode considerar as seguintes melhorias...
    """)


# --- Footer ---
st.markdown("---")
st.markdown("¬© 2025 Sistema de Interven√ß√£o Estudantil. Desenvolvido com Streamlit.")
